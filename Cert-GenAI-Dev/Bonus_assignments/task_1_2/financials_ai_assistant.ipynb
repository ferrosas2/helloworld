{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf3f0d3a",
   "metadata": {},
   "source": [
    "# Resilient Financial Services AI Assistant\n",
    "\n",
    "This notebook implements a comprehensive financial services AI assistant on Amazon Bedrock with:\n",
    "- Foundation model benchmarking across Claude and Titan models\n",
    "- Dynamic model routing with AWS AppConfig\n",
    "- Circuit breaker patterns with Step Functions\n",
    "- Cross-region deployment for high availability\n",
    "- Model lifecycle management with SageMaker\n",
    "\n",
    "**Architecture Components:**\n",
    "1. Model evaluation and selection strategy\n",
    "2. Flexible model abstraction layer\n",
    "3. Resilient system design with fallbacks\n",
    "4. Automated model customization and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18998add",
   "metadata": {},
   "source": [
    "## Section 1: Initialize AWS Clients and Configuration\n",
    "\n",
    "Set up the AWS environment, import required libraries, and initialize clients for all services used in this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d357c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "import os\n",
    "from typing import Dict, List, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a638ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ AWS clients initialized successfully\n",
      "✓ Primary Region: us-east-1\n",
      "✓ Secondary Region: us-west-2\n",
      "✓ Environment: prod\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize AWS clients\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "appconfig_client = boto3.client('appconfig', region_name='us-east-1')\n",
    "lambda_client = boto3.client('lambda', region_name='us-east-1')\n",
    "apigateway_client = boto3.client('apigateway', region_name='us-east-1')\n",
    "sfn_client = boto3.client('stepfunctions', region_name='us-east-1')\n",
    "cloudformation_client = boto3.client('cloudformation', region_name='us-east-1')\n",
    "route53_client = boto3.client('route53')\n",
    "sagemaker_client = boto3.client('sagemaker', region_name='us-east-1')\n",
    "s3_client = boto3.client('s3', region_name='us-east-1')\n",
    "cloudwatch_client = boto3.client('cloudwatch', region_name='us-east-1')\n",
    "iam_client = boto3.client('iam', region_name='us-east-1')\n",
    "\n",
    "# Configuration variables\n",
    "PRIMARY_REGION = 'us-east-1'\n",
    "SECONDARY_REGION = 'us-west-2'\n",
    "ENVIRONMENT = 'prod'\n",
    "APP_NAME = 'AIAssistantApp'\n",
    "\n",
    "# Bedrock model IDs to evaluate\n",
    "MODELS_TO_EVALUATE = [\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"anthropic.claude-instant-v1\",\n",
    "    \"amazon.titan-text-express-v1\"\n",
    "]\n",
    "\n",
    "# S3 bucket for storing datasets and models (replace with your bucket)\n",
    "S3_BUCKET = f\"cert-genai-dev/bonus_1_2/\"\n",
    "\n",
    "print(\"✓ AWS clients initialized successfully\")\n",
    "print(f\"✓ Primary Region: {PRIMARY_REGION}\")\n",
    "print(f\"✓ Secondary Region: {SECONDARY_REGION}\")\n",
    "print(f\"✓ Environment: {ENVIRONMENT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6de77b",
   "metadata": {},
   "source": [
    "## Part 1: Foundation Model Benchmarking\n",
    "\n",
    "### Section 2: Setup Evaluation Framework\n",
    "\n",
    "Implement the core evaluation infrastructure to benchmark Bedrock models on financial domain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a68e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model invocation function created\n",
      "✓ Supports Claude and Titan model families\n"
     ]
    }
   ],
   "source": [
    "def invoke_model(model_id: str, prompt: str, max_tokens: int = 500) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Invoke a Bedrock model with the given prompt and return response with metrics.\n",
    "    \n",
    "    Args:\n",
    "        model_id: The Bedrock model identifier\n",
    "        prompt: The input prompt to send to the model\n",
    "        max_tokens: Maximum tokens for the response\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing success status, output, latency, and token count\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Prepare request body based on model provider\n",
    "        if \"anthropic\" in model_id:\n",
    "            body = json.dumps({\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9\n",
    "            })\n",
    "        elif \"amazon\" in model_id:\n",
    "            body = json.dumps({\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": max_tokens,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model provider in {model_id}\")\n",
    "        \n",
    "        # Invoke the model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response_body = json.loads(response['body'].read().decode())\n",
    "        \n",
    "        # Extract output based on provider\n",
    "        if \"anthropic\" in model_id:\n",
    "            output = response_body['content'][0]['text']\n",
    "            # Approximate token count for Claude\n",
    "            token_count = len(output.split())\n",
    "        elif \"amazon\" in model_id:\n",
    "            output = response_body['results'][0]['outputText']\n",
    "            # Get actual token count if available\n",
    "            token_count = response_body['results'][0].get('tokenCount', len(output.split()))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        latency = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"output\": output,\n",
    "            \"latency\": latency,\n",
    "            \"token_count\": token_count,\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"output\": None,\n",
    "            \"latency\": time.time() - start_time,\n",
    "            \"token_count\": 0,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "print(\"✓ Model invocation function created\")\n",
    "print(\"✓ Supports Claude and Titan model families\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb38d69",
   "metadata": {},
   "source": [
    "### Section 3: Define Test Cases and Metrics\n",
    "\n",
    "Create comprehensive financial domain test cases and implement similarity scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7245183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created 7 financial domain test cases\n",
      "✓ Similarity calculation function implemented\n",
      "\n",
      "Test case categories:\n",
      "  - product_question: 4 cases\n",
      "  - account_inquiry: 1 cases\n",
      "  - compliance: 2 cases\n"
     ]
    }
   ],
   "source": [
    "# Financial domain test cases with ground truth answers\n",
    "FINANCIAL_TEST_CASES = [\n",
    "    {\n",
    "        \"question\": \"What is a 401(k) retirement plan?\",\n",
    "        \"context\": \"Retirement planning and investment accounts\",\n",
    "        \"ground_truth\": \"A 401(k) is a tax-advantaged retirement savings plan offered by employers that allows employees to contribute a portion of their salary before taxes are deducted.\",\n",
    "        \"use_case\": \"product_question\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does compound interest work?\",\n",
    "        \"context\": \"Investment fundamentals and savings growth\",\n",
    "        \"ground_truth\": \"Compound interest is when you earn interest on both your initial principal and the accumulated interest from previous periods, allowing your money to grow exponentially over time.\",\n",
    "        \"use_case\": \"product_question\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the difference between a traditional IRA and a Roth IRA?\",\n",
    "        \"context\": \"Individual retirement accounts and tax treatment\",\n",
    "        \"ground_truth\": \"A traditional IRA offers tax-deductible contributions with taxed withdrawals in retirement, while a Roth IRA uses after-tax contributions but provides tax-free withdrawals in retirement.\",\n",
    "        \"use_case\": \"product_question\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the FDIC insurance limits?\",\n",
    "        \"context\": \"Banking regulations and deposit insurance\",\n",
    "        \"ground_truth\": \"The FDIC insures deposits up to $250,000 per depositor, per insured bank, for each account ownership category, protecting customers if a bank fails.\",\n",
    "        \"use_case\": \"compliance\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I update my beneficiary information?\",\n",
    "        \"context\": \"Account management and customer service\",\n",
    "        \"ground_truth\": \"You can update your beneficiary information by logging into your account online, calling customer service at 1-800-555-1234, or visiting a branch with valid identification.\",\n",
    "        \"use_case\": \"account_inquiry\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is dollar-cost averaging?\",\n",
    "        \"context\": \"Investment strategies\",\n",
    "        \"ground_truth\": \"Dollar-cost averaging is an investment strategy where you invest a fixed amount of money at regular intervals regardless of market conditions, helping to reduce the impact of volatility.\",\n",
    "        \"use_case\": \"product_question\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What disclosures are required for securities trading?\",\n",
    "        \"context\": \"Regulatory compliance and securities law\",\n",
    "        \"ground_truth\": \"Securities trading requires disclosure of material information, risks, fees, conflicts of interest, and compliance with SEC regulations to ensure investor protection and market transparency.\",\n",
    "        \"use_case\": \"compliance\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def calculate_similarity(output: str, ground_truth: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate semantic similarity between model output and ground truth.\n",
    "    \n",
    "    This is a simplified implementation using word overlap. In production,\n",
    "    consider using embeddings-based similarity or BERT-based metrics.\n",
    "    \n",
    "    Args:\n",
    "        output: The model's generated text\n",
    "        ground_truth: The expected answer\n",
    "        \n",
    "    Returns:\n",
    "        Similarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    if not output or not ground_truth:\n",
    "        return 0.0\n",
    "    \n",
    "    # Normalize text\n",
    "    output_words = set(output.lower().split())\n",
    "    truth_words = set(ground_truth.lower().split())\n",
    "    \n",
    "    if not truth_words:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    common_words = output_words.intersection(truth_words)\n",
    "    union_words = output_words.union(truth_words)\n",
    "    \n",
    "    jaccard_score = len(common_words) / len(union_words) if union_words else 0.0\n",
    "    \n",
    "    # Calculate recall (how much of ground truth is covered)\n",
    "    recall_score = len(common_words) / len(truth_words)\n",
    "    \n",
    "    # Weighted combination (favor recall for comprehensiveness)\n",
    "    similarity = 0.4 * jaccard_score + 0.6 * recall_score\n",
    "    \n",
    "    return round(similarity, 3)\n",
    "\n",
    "print(f\"✓ Created {len(FINANCIAL_TEST_CASES)} financial domain test cases\")\n",
    "print(\"✓ Similarity calculation function implemented\")\n",
    "print(\"\\nTest case categories:\")\n",
    "for use_case in set(tc['use_case'] for tc in FINANCIAL_TEST_CASES):\n",
    "    count = sum(1 for tc in FINANCIAL_TEST_CASES if tc['use_case'] == use_case)\n",
    "    print(f\"  - {use_case}: {count} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fe9cc9",
   "metadata": {},
   "source": [
    "### Section 4: Run Model Evaluation\n",
    "\n",
    "Execute comprehensive benchmarking across all models and test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092654c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of 3 models on 7 test cases...\n",
      "Total evaluations: 21\n",
      "\n",
      "[1/21] Evaluating claude-3-sonnet-20240229-v1:0 on: What is a 401(k) retirement plan?...\n",
      "[2/21] Evaluating claude-instant-v1 on: What is a 401(k) retirement plan?...\n",
      "[3/21] Evaluating titan-text-express-v1 on: What is a 401(k) retirement plan?...\n",
      "[4/21] Evaluating claude-3-sonnet-20240229-v1:0 on: How does compound interest work?...\n",
      "[5/21] Evaluating claude-instant-v1 on: How does compound interest work?...\n",
      "[6/21] Evaluating titan-text-express-v1 on: How does compound interest work?...\n",
      "[7/21] Evaluating claude-3-sonnet-20240229-v1:0 on: What is the difference between a traditional IRA a...\n",
      "[8/21] Evaluating claude-instant-v1 on: What is the difference between a traditional IRA a...\n",
      "[9/21] Evaluating titan-text-express-v1 on: What is the difference between a traditional IRA a...\n",
      "[10/21] Evaluating claude-3-sonnet-20240229-v1:0 on: What are the FDIC insurance limits?...\n",
      "[11/21] Evaluating claude-instant-v1 on: What are the FDIC insurance limits?...\n",
      "[12/21] Evaluating titan-text-express-v1 on: What are the FDIC insurance limits?...\n",
      "[13/21] Evaluating claude-3-sonnet-20240229-v1:0 on: How do I update my beneficiary information?...\n",
      "[14/21] Evaluating claude-instant-v1 on: How do I update my beneficiary information?...\n",
      "[15/21] Evaluating titan-text-express-v1 on: How do I update my beneficiary information?...\n",
      "[16/21] Evaluating claude-3-sonnet-20240229-v1:0 on: What is dollar-cost averaging?...\n",
      "[17/21] Evaluating claude-instant-v1 on: What is dollar-cost averaging?...\n",
      "[18/21] Evaluating titan-text-express-v1 on: What is dollar-cost averaging?...\n",
      "[19/21] Evaluating claude-3-sonnet-20240229-v1:0 on: What disclosures are required for securities tradi...\n",
      "[20/21] Evaluating claude-instant-v1 on: What disclosures are required for securities tradi...\n",
      "[21/21] Evaluating titan-text-express-v1 on: What disclosures are required for securities tradi...\n",
      "\n",
      "✓ Evaluation complete!\n",
      "\n",
      "================================================================================\n",
      "EVALUATION SUMMARY\n",
      "================================================================================\n",
      "                              latency_ms                               \\\n",
      "                                    mean       std      min       max   \n",
      "model_name                                                              \n",
      "claude-3-sonnet-20240229-v1:0   8060.946  3191.903  4102.25  12350.05   \n",
      "claude-instant-v1                142.239    14.815   123.60    165.56   \n",
      "titan-text-express-v1           4382.030  3462.658  1991.37  11235.24   \n",
      "\n",
      "                              similarity_score        token_count  \\\n",
      "                                          mean    std        mean   \n",
      "model_name                                                          \n",
      "claude-3-sonnet-20240229-v1:0            0.473  0.110     209.857   \n",
      "claude-instant-v1                        0.000  0.000       0.000   \n",
      "titan-text-express-v1                    0.357  0.175      58.857   \n",
      "\n",
      "                              estimated_cost success  \n",
      "                                         sum     sum  \n",
      "model_name                                            \n",
      "claude-3-sonnet-20240229-v1:0          0.003       7  \n",
      "claude-instant-v1                      0.000       0  \n",
      "titan-text-express-v1                  0.000       7  \n",
      "\n",
      "Success rates:\n",
      "model_name                     success\n",
      "claude-3-sonnet-20240229-v1:0  True       7\n",
      "claude-instant-v1              False      7\n",
      "titan-text-express-v1          True       7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate all models on all test cases and return results DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with evaluation results including latency, quality, and errors\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_evaluations = len(MODELS_TO_EVALUATE) * len(FINANCIAL_TEST_CASES)\n",
    "    current = 0\n",
    "    \n",
    "    print(f\"Starting evaluation of {len(MODELS_TO_EVALUATE)} models on {len(FINANCIAL_TEST_CASES)} test cases...\")\n",
    "    print(f\"Total evaluations: {total_evaluations}\\n\")\n",
    "    \n",
    "    for test_case in FINANCIAL_TEST_CASES:\n",
    "        # Construct prompt with context\n",
    "        prompt = f\"\"\"Context: {test_case['context']}\n",
    "\n",
    "Question: {test_case['question']}\n",
    "\n",
    "Please provide a clear, accurate answer suitable for a financial services customer.\"\"\"\n",
    "        \n",
    "        for model_id in MODELS_TO_EVALUATE:\n",
    "            current += 1\n",
    "            print(f\"[{current}/{total_evaluations}] Evaluating {model_id.split('.')[-1]} on: {test_case['question'][:50]}...\")\n",
    "            \n",
    "            # Invoke the model\n",
    "            response = invoke_model(model_id, prompt)\n",
    "            \n",
    "            if response[\"success\"]:\n",
    "                # Calculate similarity with ground truth\n",
    "                similarity = calculate_similarity(\n",
    "                    response[\"output\"], \n",
    "                    test_case[\"ground_truth\"]\n",
    "                )\n",
    "                \n",
    "                # Estimate cost (simplified - actual costs vary by model)\n",
    "                cost_per_1k_tokens = 0.002 if \"claude-3\" in model_id else 0.001\n",
    "                estimated_cost = (response[\"token_count\"] / 1000) * cost_per_1k_tokens\n",
    "                \n",
    "                results.append({\n",
    "                    \"model_id\": model_id,\n",
    "                    \"model_name\": model_id.split('.')[-1],\n",
    "                    \"question\": test_case[\"question\"],\n",
    "                    \"use_case\": test_case[\"use_case\"],\n",
    "                    \"output\": response[\"output\"],\n",
    "                    \"ground_truth\": test_case[\"ground_truth\"],\n",
    "                    \"latency_ms\": round(response[\"latency\"] * 1000, 2),\n",
    "                    \"token_count\": response[\"token_count\"],\n",
    "                    \"similarity_score\": similarity,\n",
    "                    \"estimated_cost\": round(estimated_cost, 6),\n",
    "                    \"success\": True,\n",
    "                    \"error\": None,\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    \"model_id\": model_id,\n",
    "                    \"model_name\": model_id.split('.')[-1],\n",
    "                    \"question\": test_case[\"question\"],\n",
    "                    \"use_case\": test_case[\"use_case\"],\n",
    "                    \"output\": None,\n",
    "                    \"ground_truth\": test_case[\"ground_truth\"],\n",
    "                    \"latency_ms\": round(response[\"latency\"] * 1000, 2),\n",
    "                    \"token_count\": 0,\n",
    "                    \"similarity_score\": 0.0,\n",
    "                    \"estimated_cost\": 0.0,\n",
    "                    \"success\": False,\n",
    "                    \"error\": response[\"error\"],\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                })\n",
    "            \n",
    "            # Small delay to avoid throttling\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    print(\"\\n✓ Evaluation complete!\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run the evaluation\n",
    "results_df = evaluate_models()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = results_df.groupby(\"model_name\").agg({\n",
    "    \"latency_ms\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "    \"similarity_score\": [\"mean\", \"std\"],\n",
    "    \"token_count\": \"mean\",\n",
    "    \"estimated_cost\": \"sum\",\n",
    "    \"success\": \"sum\"\n",
    "}).round(3)\n",
    "\n",
    "print(summary)\n",
    "print(\"\\nSuccess rates:\")\n",
    "print(results_df.groupby(\"model_name\")[\"success\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeab8a9",
   "metadata": {},
   "source": [
    "### Section 5: Analyze Results and Create Selection Strategy\n",
    "\n",
    "Process evaluation results to create an intelligent model selection strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a86479f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL SELECTION STRATEGY\n",
      "================================================================================\n",
      "\n",
      "Primary Model: amazon.titan-text-express-v1\n",
      "Fallback Models: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "\n",
      "Use Case Assignments:\n",
      "  - product_question: claude-3-sonnet-20240229-v1:0\n",
      "  - compliance: claude-3-sonnet-20240229-v1:0\n",
      "  - account_inquiry: claude-3-sonnet-20240229-v1:0\n",
      "\n",
      "✓ Saved evaluation results to: model_evaluation_results.csv\n",
      "✓ Saved selection strategy to: model_selection_strategy.json\n"
     ]
    }
   ],
   "source": [
    "def create_model_selection_strategy(results_df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a model selection strategy based on evaluation results.\n",
    "    \n",
    "    Analyzes quality, latency, and cost to rank models and assign them\n",
    "    to specific use cases.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with evaluation results\n",
    "        \n",
    "    Returns:\n",
    "        Strategy dictionary for AppConfig\n",
    "    \"\"\"\n",
    "    # Filter successful evaluations only\n",
    "    successful_df = results_df[results_df[\"success\"] == True].copy()\n",
    "    \n",
    "    # Calculate aggregate metrics by model\n",
    "    model_scores = successful_df.groupby(\"model_id\").agg({\n",
    "        \"latency_ms\": \"mean\",\n",
    "        \"similarity_score\": \"mean\",\n",
    "        \"estimated_cost\": \"sum\",\n",
    "        \"success\": \"count\"\n",
    "    }).reset_index()\n",
    "    \n",
    "    model_scores.columns = [\"model_id\", \"avg_latency_ms\", \"avg_similarity\", \"total_cost\", \"num_evaluations\"]\n",
    "    \n",
    "    # Normalize scores (0-1 scale)\n",
    "    if len(model_scores) > 0:\n",
    "        max_latency = model_scores[\"avg_latency_ms\"].max()\n",
    "        max_cost = model_scores[\"total_cost\"].max()\n",
    "        \n",
    "        # Lower latency is better, so invert\n",
    "        model_scores[\"latency_score\"] = 1 - (model_scores[\"avg_latency_ms\"] / max_latency)\n",
    "        \n",
    "        # Lower cost is better, so invert\n",
    "        model_scores[\"cost_score\"] = 1 - (model_scores[\"total_cost\"] / max_cost) if max_cost > 0 else 1.0\n",
    "        \n",
    "        # Higher similarity is better (already 0-1)\n",
    "        model_scores[\"quality_score\"] = model_scores[\"avg_similarity\"]\n",
    "        \n",
    "        # Calculate weighted overall score\n",
    "        # Weights: Quality 50%, Latency 30%, Cost 20% (adjust for your priorities)\n",
    "        model_scores[\"overall_score\"] = (\n",
    "            0.50 * model_scores[\"quality_score\"] +\n",
    "            0.30 * model_scores[\"latency_score\"] +\n",
    "            0.20 * model_scores[\"cost_score\"]\n",
    "        )\n",
    "        \n",
    "        # Sort by overall score\n",
    "        model_scores = model_scores.sort_values(\"overall_score\", ascending=False)\n",
    "    \n",
    "    # Determine use case specific models\n",
    "    use_case_models = {}\n",
    "    \n",
    "    for use_case in successful_df[\"use_case\"].unique():\n",
    "        use_case_df = successful_df[successful_df[\"use_case\"] == use_case]\n",
    "        use_case_scores = use_case_df.groupby(\"model_id\")[\"similarity_score\"].mean()\n",
    "        best_model = use_case_scores.idxmax()\n",
    "        use_case_models[use_case] = best_model\n",
    "    \n",
    "    # Create strategy\n",
    "    strategy = {\n",
    "        \"version\": \"1.0\",\n",
    "        \"last_updated\": datetime.now().isoformat(),\n",
    "        \"primary_model\": model_scores.iloc[0][\"model_id\"] if len(model_scores) > 0 else MODELS_TO_EVALUATE[0],\n",
    "        \"fallback_models\": model_scores.iloc[1:][\"model_id\"].tolist() if len(model_scores) > 1 else [],\n",
    "        \"use_case_models\": use_case_models,\n",
    "        \"model_scores\": model_scores.to_dict(orient=\"records\"),\n",
    "        \"thresholds\": {\n",
    "            \"max_latency_ms\": 5000,\n",
    "            \"min_similarity_score\": 0.3,\n",
    "            \"max_cost_per_request\": 0.01\n",
    "        },\n",
    "        \"guardrails\": {\n",
    "            \"content_filters\": [\"profanity\", \"pii\", \"financial_advice_disclaimer\"],\n",
    "            \"max_retries\": 3,\n",
    "            \"circuit_breaker_threshold\": 5\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return strategy\n",
    "\n",
    "# Create the strategy\n",
    "strategy = create_model_selection_strategy(results_df)\n",
    "\n",
    "# Display the strategy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL SELECTION STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPrimary Model: {strategy['primary_model']}\")\n",
    "print(f\"Fallback Models: {', '.join(strategy['fallback_models'])}\")\n",
    "print(\"\\nUse Case Assignments:\")\n",
    "for use_case, model in strategy['use_case_models'].items():\n",
    "    print(f\"  - {use_case}: {model.split('.')[-1]}\")\n",
    "\n",
    "# Save results and strategy to files\n",
    "results_df.to_csv(\"model_evaluation_results.csv\", index=False)\n",
    "print(\"\\n✓ Saved evaluation results to: model_evaluation_results.csv\")\n",
    "\n",
    "with open(\"model_selection_strategy.json\", \"w\") as f:\n",
    "    json.dump(strategy, f, indent=2)\n",
    "print(\"✓ Saved selection strategy to: model_selection_strategy.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef676fd6",
   "metadata": {},
   "source": [
    "## Part 2: Flexible Architecture for Dynamic Model Selection\n",
    "\n",
    "### Section 6: Configure AWS AppConfig\n",
    "\n",
    "Set up AppConfig to manage model selection strategy dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890cb863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating AppConfig application...\n",
      "✓ Created application: vb86etf\n",
      "Creating environment...\n",
      "✓ Created environment: 28u8itm\n",
      "Creating configuration profile...\n",
      "✓ Created configuration profile: 6o43wqr\n",
      "Creating configuration version...\n",
      "✓ Created configuration version: 1\n",
      "Setting up deployment strategy...\n",
      "✓ Created deployment strategy: g1y56tt\n",
      "\n",
      "✓ AppConfig setup complete!\n",
      "\n",
      "AppConfig Resource IDs:\n",
      "  application_id: vb86etf\n",
      "  environment_id: 28u8itm\n",
      "  configuration_profile_id: 6o43wqr\n",
      "  deployment_strategy_id: g1y56tt\n"
     ]
    }
   ],
   "source": [
    "def setup_appconfig():\n",
    "    \"\"\"\n",
    "    Create AWS AppConfig application, environment, and configuration profile.\n",
    "    Deploy the model selection strategy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create application\n",
    "        print(\"Creating AppConfig application...\")\n",
    "        try:\n",
    "            app_response = appconfig_client.create_application(\n",
    "                Name=APP_NAME,\n",
    "                Description=\"AI Assistant model selection configuration\"\n",
    "            )\n",
    "            app_id = app_response['Id']\n",
    "            print(f\"✓ Created application: {app_id}\")\n",
    "        except appconfig_client.exceptions.ResourceNotFoundException:\n",
    "            # Application might already exist\n",
    "            apps = appconfig_client.list_applications()\n",
    "            app_id = next((app['Id'] for app in apps['Items'] if app['Name'] == APP_NAME), None)\n",
    "            if app_id:\n",
    "                print(f\"✓ Using existing application: {app_id}\")\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Create environment\n",
    "        print(\"Creating environment...\")\n",
    "        try:\n",
    "            env_response = appconfig_client.create_environment(\n",
    "                ApplicationId=app_id,\n",
    "                Name=ENVIRONMENT,\n",
    "                Description=f\"{ENVIRONMENT} environment for AI Assistant\"\n",
    "            )\n",
    "            env_id = env_response['Id']\n",
    "            print(f\"✓ Created environment: {env_id}\")\n",
    "        except:\n",
    "            # Environment might already exist\n",
    "            envs = appconfig_client.list_environments(ApplicationId=app_id)\n",
    "            env_id = next((env['Id'] for env in envs['Items'] if env['Name'] == ENVIRONMENT), None)\n",
    "            if env_id:\n",
    "                print(f\"✓ Using existing environment: {env_id}\")\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Create configuration profile\n",
    "        print(\"Creating configuration profile...\")\n",
    "        try:\n",
    "            profile_response = appconfig_client.create_configuration_profile(\n",
    "                ApplicationId=app_id,\n",
    "                Name=\"ModelSelectionStrategy\",\n",
    "                Description=\"Dynamic model selection and routing strategy\",\n",
    "                LocationUri=\"hosted\",\n",
    "                Type=\"AWS.Freeform\"\n",
    "            )\n",
    "            profile_id = profile_response['Id']\n",
    "            print(f\"✓ Created configuration profile: {profile_id}\")\n",
    "        except:\n",
    "            # Profile might already exist\n",
    "            profiles = appconfig_client.list_configuration_profiles(ApplicationId=app_id)\n",
    "            profile_id = next((p['Id'] for p in profiles['Items'] if p['Name'] == \"ModelSelectionStrategy\"), None)\n",
    "            if profile_id:\n",
    "                print(f\"✓ Using existing configuration profile: {profile_id}\")\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Create hosted configuration version\n",
    "        print(\"Creating configuration version...\")\n",
    "        with open(\"model_selection_strategy.json\", \"r\") as f:\n",
    "            config_content = f.read()\n",
    "        \n",
    "        version_response = appconfig_client.create_hosted_configuration_version(\n",
    "            ApplicationId=app_id,\n",
    "            ConfigurationProfileId=profile_id,\n",
    "            Content=config_content.encode('utf-8'),\n",
    "            ContentType=\"application/json\",\n",
    "            Description=f\"Model selection strategy - {datetime.now().isoformat()}\"\n",
    "        )\n",
    "        version_number = version_response['VersionNumber']\n",
    "        print(f\"✓ Created configuration version: {version_number}\")\n",
    "        \n",
    "        # Create deployment strategy (if needed)\n",
    "        print(\"Setting up deployment strategy...\")\n",
    "        try:\n",
    "            strategy_response = appconfig_client.create_deployment_strategy(\n",
    "                Name=\"FastDeployment\",\n",
    "                Description=\"Deploy configuration changes immediately\",\n",
    "                DeploymentDurationInMinutes=0,\n",
    "                GrowthFactor=100,\n",
    "                ReplicateTo=\"NONE\"\n",
    "            )\n",
    "            strategy_id = strategy_response['Id']\n",
    "            print(f\"✓ Created deployment strategy: {strategy_id}\")\n",
    "        except:\n",
    "            # Use predefined strategy\n",
    "            strategy_id = \"AppConfig.AllAtOnce\"\n",
    "            print(f\"✓ Using predefined deployment strategy: {strategy_id}\")\n",
    "        \n",
    "        print(\"\\n✓ AppConfig setup complete!\")\n",
    "        \n",
    "        return {\n",
    "            \"application_id\": app_id,\n",
    "            \"environment_id\": env_id,\n",
    "            \"configuration_profile_id\": profile_id,\n",
    "            \"deployment_strategy_id\": strategy_id\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error setting up AppConfig: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Set up AppConfig\n",
    "appconfig_info = setup_appconfig()\n",
    "\n",
    "if appconfig_info:\n",
    "    print(\"\\nAppConfig Resource IDs:\")\n",
    "    for key, value in appconfig_info.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0a939",
   "metadata": {},
   "source": [
    "### Section 7: Implement Model Abstraction Lambda\n",
    "\n",
    "Create the Lambda function that dynamically selects and invokes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41382a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Lambda function code saved to: model_abstraction_lambda.py\n",
      "\n",
      "To deploy this Lambda function:\n",
      "1. Create a deployment package with dependencies (boto3 is included in Lambda by default)\n",
      "2. Create IAM role with permissions for Bedrock and AppConfig\n",
      "3. Deploy using AWS CLI, Console, or SAM/CDK\n"
     ]
    }
   ],
   "source": [
    "# Lambda function code for model abstraction\n",
    "MODEL_ABSTRACTION_LAMBDA_CODE = '''\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "appconfig_client = boto3.client('appconfig')\n",
    "\n",
    "# Cache configuration\n",
    "config_cache = {\n",
    "    \"data\": None,\n",
    "    \"timestamp\": None,\n",
    "    \"ttl\": 300  # 5 minutes\n",
    "}\n",
    "\n",
    "def get_configuration():\n",
    "    \"\"\"Retrieve configuration from AppConfig with caching.\"\"\"\n",
    "    current_time = datetime.now().timestamp()\n",
    "    \n",
    "    # Check cache\n",
    "    if (config_cache[\"data\"] is not None and \n",
    "        config_cache[\"timestamp\"] is not None and\n",
    "        current_time - config_cache[\"timestamp\"] < config_cache[\"ttl\"]):\n",
    "        return config_cache[\"data\"]\n",
    "    \n",
    "    # Fetch fresh configuration\n",
    "    try:\n",
    "        response = appconfig_client.get_configuration(\n",
    "            Application=os.environ['APP_NAME'],\n",
    "            Environment=os.environ['ENVIRONMENT'],\n",
    "            Configuration='ModelSelectionStrategy',\n",
    "            ClientId='model-abstraction-lambda'\n",
    "        )\n",
    "        \n",
    "        config = json.loads(response['Content'].read().decode('utf-8'))\n",
    "        \n",
    "        # Update cache\n",
    "        config_cache[\"data\"] = config\n",
    "        config_cache[\"timestamp\"] = current_time\n",
    "        \n",
    "        return config\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching configuration: {str(e)}\")\n",
    "        # Return cached data if available\n",
    "        return config_cache[\"data\"]\n",
    "\n",
    "def select_model(config, use_case):\n",
    "    \"\"\"Select appropriate model based on configuration and use case.\"\"\"\n",
    "    if not config:\n",
    "        return None\n",
    "    \n",
    "    # Check for use case specific model\n",
    "    use_case_models = config.get('use_case_models', {})\n",
    "    if use_case in use_case_models:\n",
    "        return use_case_models[use_case]\n",
    "    \n",
    "    # Default to primary model\n",
    "    return config.get('primary_model')\n",
    "\n",
    "def invoke_model(model_id, prompt, max_tokens=500):\n",
    "    \"\"\"Invoke the selected Bedrock model.\"\"\"\n",
    "    try:\n",
    "        # Prepare request based on model provider\n",
    "        if \"anthropic\" in model_id:\n",
    "            body = json.dumps({\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9\n",
    "            })\n",
    "        elif \"amazon\" in model_id:\n",
    "            body = json.dumps({\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": max_tokens,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_id}\")\n",
    "        \n",
    "        # Invoke model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        response_body = json.loads(response['body'].read().decode())\n",
    "        \n",
    "        if \"anthropic\" in model_id:\n",
    "            output = response_body['content'][0]['text']\n",
    "        elif \"amazon\" in model_id:\n",
    "            output = response_body['results'][0]['outputText']\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"output\": output,\n",
    "            \"model_used\": model_id\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"model_used\": model_id\n",
    "        }\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"Main Lambda handler for model abstraction.\"\"\"\n",
    "    try:\n",
    "        # Parse request\n",
    "        body = json.loads(event.get('body', '{}'))\n",
    "        prompt = body.get('prompt', '')\n",
    "        use_case = body.get('use_case', 'general')\n",
    "        max_tokens = body.get('max_tokens', 500)\n",
    "        \n",
    "        # Validate input\n",
    "        if not prompt:\n",
    "            return {\n",
    "                'statusCode': 400,\n",
    "                'body': json.dumps({'error': 'Prompt is required'})\n",
    "            }\n",
    "        \n",
    "        # Get configuration\n",
    "        config = get_configuration()\n",
    "        if not config:\n",
    "            return {\n",
    "                'statusCode': 500,\n",
    "                'body': json.dumps({'error': 'Failed to load configuration'})\n",
    "            }\n",
    "        \n",
    "        # Select model\n",
    "        model_id = select_model(config, use_case)\n",
    "        if not model_id:\n",
    "            return {\n",
    "                'statusCode': 500,\n",
    "                'body': json.dumps({'error': 'No model available for use case'})\n",
    "            }\n",
    "        \n",
    "        # Invoke model with retries\n",
    "        max_retries = config.get('guardrails', {}).get('max_retries', 3)\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            result = invoke_model(model_id, prompt, max_tokens)\n",
    "            \n",
    "            if result[\"success\"]:\n",
    "                return {\n",
    "                    'statusCode': 200,\n",
    "                    'body': json.dumps({\n",
    "                        'response': result[\"output\"],\n",
    "                        'model_used': result[\"model_used\"],\n",
    "                        'use_case': use_case,\n",
    "                        'attempt': attempt + 1\n",
    "                    }),\n",
    "                    'headers': {\n",
    "                        'Content-Type': 'application/json'\n",
    "                    }\n",
    "                }\n",
    "        \n",
    "        # All retries failed\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps({\n",
    "                'error': 'Model invocation failed after retries',\n",
    "                'model_used': model_id\n",
    "            })\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps({'error': str(e)})\n",
    "        }\n",
    "'''\n",
    "\n",
    "# Save Lambda code to file\n",
    "with open(\"model_abstraction_lambda.py\", \"w\") as f:\n",
    "    f.write(MODEL_ABSTRACTION_LAMBDA_CODE)\n",
    "\n",
    "print(\"✓ Lambda function code saved to: model_abstraction_lambda.py\")\n",
    "print(\"\\nTo deploy this Lambda function:\")\n",
    "print(\"1. Create a deployment package with dependencies (boto3 is included in Lambda by default)\")\n",
    "print(\"2. Create IAM role with permissions for Bedrock and AppConfig\")\n",
    "print(\"3. Deploy using AWS CLI, Console, or SAM/CDK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e66ba",
   "metadata": {},
   "source": [
    "### Section 8: Deploy API Gateway Integration\n",
    "\n",
    "Set up API Gateway to expose the Lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caead64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Gateway Integration Setup\n",
      "================================================================================\n",
      "\n",
      "To complete the setup:\n",
      "1. Deploy the model_abstraction_lambda.py function to AWS Lambda\n",
      "2. Note the Lambda ARN\n",
      "3. Run: create_api_gateway_integration(lambda_arn)\n",
      "\n",
      "Example usage:\n",
      "  api_info = create_api_gateway_integration('arn:aws:lambda:us-east-1:123456789012:function:ModelAbstraction')\n"
     ]
    }
   ],
   "source": [
    "def create_api_gateway_integration(lambda_arn):\n",
    "    \"\"\"\n",
    "    Create API Gateway REST API with Lambda integration.\n",
    "    \n",
    "    Args:\n",
    "        lambda_arn: ARN of the model abstraction Lambda function\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with API Gateway details\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create REST API\n",
    "        print(\"Creating REST API...\")\n",
    "        api_response = apigateway_client.create_rest_api(\n",
    "            name=f\"{APP_NAME}-API\",\n",
    "            description=\"API for AI Assistant model abstraction\",\n",
    "            endpointConfiguration={'types': ['REGIONAL']}\n",
    "        )\n",
    "        api_id = api_response['id']\n",
    "        print(f\"✓ Created API: {api_id}\")\n",
    "        \n",
    "        # Get root resource\n",
    "        resources = apigateway_client.get_resources(restApiId=api_id)\n",
    "        root_id = resources['items'][0]['id']\n",
    "        \n",
    "        # Create /generate resource\n",
    "        print(\"Creating /generate resource...\")\n",
    "        resource_response = apigateway_client.create_resource(\n",
    "            restApiId=api_id,\n",
    "            parentId=root_id,\n",
    "            pathPart='generate'\n",
    "        )\n",
    "        resource_id = resource_response['id']\n",
    "        print(f\"✓ Created resource: {resource_id}\")\n",
    "        \n",
    "        # Create POST method\n",
    "        print(\"Creating POST method...\")\n",
    "        apigateway_client.put_method(\n",
    "            restApiId=api_id,\n",
    "            resourceId=resource_id,\n",
    "            httpMethod='POST',\n",
    "            authorizationType='NONE',\n",
    "            apiKeyRequired=False\n",
    "        )\n",
    "        print(\"✓ Created POST method\")\n",
    "        \n",
    "        # Set up Lambda integration\n",
    "        print(\"Setting up Lambda integration...\")\n",
    "        region = boto3.session.Session().region_name\n",
    "        uri = f\"arn:aws:apigateway:{region}:lambda:path/2015-03-31/functions/{lambda_arn}/invocations\"\n",
    "        \n",
    "        apigateway_client.put_integration(\n",
    "            restApiId=api_id,\n",
    "            resourceId=resource_id,\n",
    "            httpMethod='POST',\n",
    "            type='AWS_PROXY',\n",
    "            integrationHttpMethod='POST',\n",
    "            uri=uri\n",
    "        )\n",
    "        print(\"✓ Configured Lambda integration\")\n",
    "        \n",
    "        # Create method response\n",
    "        apigateway_client.put_method_response(\n",
    "            restApiId=api_id,\n",
    "            resourceId=resource_id,\n",
    "            httpMethod='POST',\n",
    "            statusCode='200',\n",
    "            responseModels={'application/json': 'Empty'}\n",
    "        )\n",
    "        \n",
    "        # Deploy API\n",
    "        print(f\"Deploying API to {ENVIRONMENT} stage...\")\n",
    "        deployment = apigateway_client.create_deployment(\n",
    "            restApiId=api_id,\n",
    "            stageName=ENVIRONMENT,\n",
    "            description=f\"Deployment at {datetime.now().isoformat()}\"\n",
    "        )\n",
    "        print(f\"✓ Deployed API: {deployment['id']}\")\n",
    "        \n",
    "        # Construct endpoint URL\n",
    "        endpoint_url = f\"https://{api_id}.execute-api.{region}.amazonaws.com/{ENVIRONMENT}/generate\"\n",
    "        \n",
    "        print(\"\\n✓ API Gateway setup complete!\")\n",
    "        print(f\"\\nEndpoint URL: {endpoint_url}\")\n",
    "        \n",
    "        return {\n",
    "            \"api_id\": api_id,\n",
    "            \"resource_id\": resource_id,\n",
    "            \"deployment_id\": deployment['id'],\n",
    "            \"endpoint_url\": endpoint_url\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error creating API Gateway: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Note: This would require an actual Lambda ARN\n",
    "# For demonstration, we'll show the structure\n",
    "print(\"API Gateway Integration Setup\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTo complete the setup:\")\n",
    "print(\"1. Deploy the model_abstraction_lambda.py function to AWS Lambda\")\n",
    "print(\"2. Note the Lambda ARN\")\n",
    "print(\"3. Run: create_api_gateway_integration(lambda_arn)\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"  api_info = create_api_gateway_integration('arn:aws:lambda:us-east-1:123456789012:function:ModelAbstraction')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84aa565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating REST API...\n",
      "✓ Created API: qqskzpxhgb\n",
      "Creating /generate resource...\n",
      "✓ Created resource: wxx8f9\n",
      "Creating POST method...\n",
      "✓ Created POST method\n",
      "Setting up Lambda integration...\n",
      "✓ Configured Lambda integration\n",
      "Deploying API to prod stage...\n",
      "✓ Deployed API: he6plk\n",
      "\n",
      "✓ API Gateway setup complete!\n",
      "\n",
      "Endpoint URL: https://qqskzpxhgb.execute-api.us-east-1.amazonaws.com/prod/generate\n",
      "\n",
      "API Gateway ID: qqskzpxhgb\n",
      "Test Command: curl -X POST https://qqskzpxhgb.execute-api.us-east-1.amazonaws.com/prod/generate -d '{\"prompt\": \"What is a 401k?\", \"use_case\": \"product_question\"}'\n"
     ]
    }
   ],
   "source": [
    "# Deploy API Gateway integration using the deployed Lambda ARN\n",
    "lambda_arn = 'arn:aws:lambda:us-east-1:091366569168:function:ModelAbstractionLambda'\n",
    "api_info = create_api_gateway_integration(lambda_arn)\n",
    "\n",
    "if api_info:\n",
    "    print(f\"\\nAPI Gateway ID: {api_info['api_id']}\")\n",
    "    print(f\"Test Command: curl -X POST {api_info['endpoint_url']} -d '{{\\\"prompt\\\": \\\"What is a 401k?\\\", \\\"use_case\\\": \\\"product_question\\\"}}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5b9ed",
   "metadata": {},
   "source": [
    "- Here is the right CLI:\n",
    "```powershell\n",
    "Invoke-RestMethod -Uri \"https://qqskzpxhgb.execute-api.us-east-1.amazonaws.com/prod/generate\" -Method Post -Body '{\"prompt\": \"What is a 401k?\", \"use_case\": \"product_question\"}' -ContentType \"application/json\"\n",
    "```\n",
    "- Response:\n",
    "\n",
    "A 401(k) is a tax-advantaged retirement savings plan offered by many employers in the United States. It allows employees to contribute a portion of their pre-tax salary to individual accounts, which can then be invested in various financial products such as stocks, bonds, and mutual funds. Employers may also offer matching contributions to encourage participation. The funds in a 401(k) grow tax-deferred until withdrawal, typically at retirement age, when they are taxed as ordinary income. Early withdrawals before age 59½ may incur penalties and taxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c6a26",
   "metadata": {},
   "source": [
    "## Part 3: Resilient System Design\n",
    "\n",
    "### Section 9: Create Step Functions Circuit Breaker\n",
    "\n",
    "Implement circuit breaker pattern with Step Functions for resilient model invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Step Functions state machine definition saved to: circuit_breaker_state_machine.json\n",
      "\n",
      "Circuit Breaker Features:\n",
      "  ✓ Primary model invocation with retries\n",
      "  ✓ Automatic fallback to secondary model\n",
      "  ✓ Failure count tracking in DynamoDB\n",
      "  ✓ Circuit breaker opens after 5 failures\n",
      "  ✓ Graceful degradation when all models fail\n",
      "  ✓ Success resets failure count\n"
     ]
    }
   ],
   "source": [
    "# Step Functions state machine definition\n",
    "CIRCUIT_BREAKER_STATE_MACHINE = {\n",
    "    \"Comment\": \"AI Assistant with Circuit Breaker Pattern for Resilient Model Invocation\",\n",
    "    \"StartAt\": \"TryPrimaryModel\",\n",
    "    \"States\": {\n",
    "        \"TryPrimaryModel\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:states:::lambda:invoke\",\n",
    "            \"Parameters\": {\n",
    "                \"FunctionName\": \"${PrimaryModelLambdaArn}\",\n",
    "                \"Payload\": {\n",
    "                    \"prompt.$\": \"$.prompt\",\n",
    "                    \"use_case.$\": \"$.use_case\",\n",
    "                    \"max_tokens.$\": \"$.max_tokens\"\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.primaryResult\",\n",
    "            \"Retry\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\n",
    "                        \"Lambda.ServiceException\",\n",
    "                        \"Lambda.TooManyRequestsException\"\n",
    "                    ],\n",
    "                    \"IntervalSeconds\": 2,\n",
    "                    \"MaxAttempts\": 2,\n",
    "                    \"BackoffRate\": 2.0\n",
    "                }\n",
    "            ],\n",
    "            \"Catch\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"States.ALL\"],\n",
    "                    \"ResultPath\": \"$.primaryError\",\n",
    "                    \"Next\": \"IncrementFailureCount\"\n",
    "                }\n",
    "            ],\n",
    "            \"Next\": \"ResetFailureCount\"\n",
    "        },\n",
    "        \"IncrementFailureCount\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:states:::dynamodb:updateItem\",\n",
    "            \"Parameters\": {\n",
    "                \"TableName\": \"${CircuitBreakerTable}\",\n",
    "                \"Key\": {\n",
    "                    \"circuitId\": {\"S\": \"primary-model\"}\n",
    "                },\n",
    "                \"UpdateExpression\": \"ADD failureCount :inc SET lastFailure = :timestamp\",\n",
    "                \"ExpressionAttributeValues\": {\n",
    "                    \":inc\": {\"N\": \"1\"},\n",
    "                    \":timestamp\": {\"S.$\": \"$$.State.EnteredTime\"}\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.circuitState\",\n",
    "            \"Next\": \"CheckCircuitBreaker\"\n",
    "        },\n",
    "        \"CheckCircuitBreaker\": {\n",
    "            \"Type\": \"Choice\",\n",
    "            \"Choices\": [\n",
    "                {\n",
    "                    \"Variable\": \"$.circuitState.Attributes.failureCount.N\",\n",
    "                    \"NumericGreaterThan\": 5,\n",
    "                    \"Next\": \"CircuitOpen\"\n",
    "                }\n",
    "            ],\n",
    "            \"Default\": \"TryFallbackModel\"\n",
    "        },\n",
    "        \"CircuitOpen\": {\n",
    "            \"Type\": \"Pass\",\n",
    "            \"Result\": {\n",
    "                \"status\": \"circuit_open\",\n",
    "                \"message\": \"Circuit breaker open due to repeated failures\"\n",
    "            },\n",
    "            \"ResultPath\": \"$.circuitStatus\",\n",
    "            \"Next\": \"GracefulDegradation\"\n",
    "        },\n",
    "        \"TryFallbackModel\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:states:::lambda:invoke\",\n",
    "            \"Parameters\": {\n",
    "                \"FunctionName\": \"${FallbackModelLambdaArn}\",\n",
    "                \"Payload\": {\n",
    "                    \"prompt.$\": \"$.prompt\",\n",
    "                    \"use_case.$\": \"$.use_case\",\n",
    "                    \"is_fallback\": True\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.fallbackResult\",\n",
    "            \"Retry\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\n",
    "                        \"Lambda.ServiceException\",\n",
    "                        \"Lambda.TooManyRequestsException\"\n",
    "                    ],\n",
    "                    \"IntervalSeconds\": 1,\n",
    "                    \"MaxAttempts\": 2,\n",
    "                    \"BackoffRate\": 2.0\n",
    "                }\n",
    "            ],\n",
    "            \"Catch\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"States.ALL\"],\n",
    "                    \"ResultPath\": \"$.fallbackError\",\n",
    "                    \"Next\": \"GracefulDegradation\"\n",
    "                }\n",
    "            ],\n",
    "            \"Next\": \"SuccessState\"\n",
    "        },\n",
    "        \"GracefulDegradation\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:states:::lambda:invoke\",\n",
    "            \"Parameters\": {\n",
    "                \"FunctionName\": \"${DegradationLambdaArn}\",\n",
    "                \"Payload\": {\n",
    "                    \"prompt.$\": \"$.prompt\",\n",
    "                    \"use_case.$\": \"$.use_case\",\n",
    "                    \"reason\": \"all_models_failed\"\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.degradationResult\",\n",
    "            \"Next\": \"SuccessState\"\n",
    "        },\n",
    "        \"ResetFailureCount\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:states:::dynamodb:updateItem\",\n",
    "            \"Parameters\": {\n",
    "                \"TableName\": \"${CircuitBreakerTable}\",\n",
    "                \"Key\": {\n",
    "                    \"circuitId\": {\"S\": \"primary-model\"}\n",
    "                },\n",
    "                \"UpdateExpression\": \"SET failureCount = :zero, lastSuccess = :timestamp\",\n",
    "                \"ExpressionAttributeValues\": {\n",
    "                    \":zero\": {\"N\": \"0\"},\n",
    "                    \":timestamp\": {\"S.$\": \"$$.State.EnteredTime\"}\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.resetResult\",\n",
    "            \"Next\": \"SuccessState\"\n",
    "        },\n",
    "        \"SuccessState\": {\n",
    "            \"Type\": \"Succeed\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save state machine definition\n",
    "with open(\"circuit_breaker_state_machine.json\", \"w\") as f:\n",
    "    json.dump(CIRCUIT_BREAKER_STATE_MACHINE, f, indent=2)\n",
    "\n",
    "print(\"✓ Step Functions state machine definition saved to: circuit_breaker_state_machine.json\")\n",
    "print(\"\\nCircuit Breaker Features:\")\n",
    "print(\"  ✓ Primary model invocation with retries\")\n",
    "print(\"  ✓ Automatic fallback to secondary model\")\n",
    "print(\"  ✓ Failure count tracking in DynamoDB\")\n",
    "print(\"  ✓ Circuit breaker opens after 5 failures\")\n",
    "print(\"  ✓ Graceful degradation when all models fail\")\n",
    "print(\"  ✓ Success resets failure count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c4a2a",
   "metadata": {},
   "source": [
    "### Section 10: Implement Fallback Lambda\n",
    "\n",
    "Create the fallback Lambda that uses a simpler, more reliable model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c273ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fallback Lambda code saved to: fallback_model_lambda.py\n",
      "\n",
      "Fallback Lambda Features:\n",
      "  ✓ Uses Amazon Titan Express (simpler model)\n",
      "  ✓ Reduced max tokens (300) for faster response\n",
      "  ✓ Lower temperature (0.5) for consistency\n",
      "  ✓ Marks responses with FALLBACK prefix\n",
      "  ✓ Propagates errors to Step Functions for graceful degradation\n"
     ]
    }
   ],
   "source": [
    "# Fallback model Lambda code\n",
    "FALLBACK_MODEL_LAMBDA_CODE = '''\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Fallback model handler that uses a simpler, more reliable model.\n",
    "    \n",
    "    This Lambda is invoked when the primary model fails, using\n",
    "    conservative settings for maximum reliability.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract parameters\n",
    "        prompt = event.get('prompt', '')\n",
    "        use_case = event.get('use_case', 'general')\n",
    "        is_fallback = event.get('is_fallback', False)\n",
    "        \n",
    "        # Use Titan Express as fallback (simpler, more reliable)\n",
    "        model_id = \"amazon.titan-text-express-v1\"\n",
    "        \n",
    "        # Conservative parameters for reliability\n",
    "        body = json.dumps({\n",
    "            \"inputText\": prompt,\n",
    "            \"textGenerationConfig\": {\n",
    "                \"maxTokenCount\": 300,  # Reduced for faster response\n",
    "                \"temperature\": 0.5,    # Lower temperature for consistency\n",
    "                \"topP\": 0.9,\n",
    "                \"stopSequences\": []\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Invoke model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        response_body = json.loads(response['body'].read().decode())\n",
    "        output = response_body['results'][0]['outputText']\n",
    "        \n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps({\n",
    "                'response': output,\n",
    "                'model_used': f\"FALLBACK:{model_id}\",\n",
    "                'use_case': use_case,\n",
    "                'is_fallback': True,\n",
    "                'message': 'Fallback model used due to primary model failure'\n",
    "            })\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Even fallback failed - let Step Functions handle\n",
    "        raise Exception(f\"Fallback model failed: {str(e)}\")\n",
    "'''\n",
    "\n",
    "# Save fallback Lambda code\n",
    "with open(\"fallback_model_lambda.py\", \"w\") as f:\n",
    "    f.write(FALLBACK_MODEL_LAMBDA_CODE)\n",
    "\n",
    "print(\"✓ Fallback Lambda code saved to: fallback_model_lambda.py\")\n",
    "print(\"\\nFallback Lambda Features:\")\n",
    "print(\"  ✓ Uses Amazon Titan Express (simpler model)\")\n",
    "print(\"  ✓ Reduced max tokens (300) for faster response\")\n",
    "print(\"  ✓ Lower temperature (0.5) for consistency\")\n",
    "print(\"  ✓ Marks responses with FALLBACK prefix\")\n",
    "print(\"  ✓ Propagates errors to Step Functions for graceful degradation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3ae96",
   "metadata": {},
   "source": [
    "### Section 11: Implement Graceful Degradation Lambda\n",
    "\n",
    "Create the final safety net with predefined regulation-safe responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7120e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Graceful degradation Lambda code saved to: graceful_degradation_lambda.py\n",
      "\n",
      "Graceful Degradation Features:\n",
      "  ✓ Predefined responses by use case\n",
      "  ✓ Regulation-compliant messaging\n",
      "  ✓ Contact information for each scenario\n",
      "  ✓ Standard FDIC and financial disclaimers\n",
      "  ✓ Marked as DEGRADED_SERVICE for monitoring\n",
      "  ✓ Always returns 200 status with helpful guidance\n"
     ]
    }
   ],
   "source": [
    "# Graceful degradation Lambda code\n",
    "GRACEFUL_DEGRADATION_LAMBDA_CODE = '''\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Graceful degradation handler that returns predefined, regulation-safe responses.\n",
    "    \n",
    "    This is the final safety net when all models fail, ensuring customers\n",
    "    always receive helpful guidance that complies with financial regulations.\n",
    "    \"\"\"\n",
    "    prompt = event.get('prompt', '')\n",
    "    use_case = event.get('use_case', 'general')\n",
    "    reason = event.get('reason', 'unknown')\n",
    "    \n",
    "    # Regulation-compliant responses by use case\n",
    "    responses = {\n",
    "        \"general\": {\n",
    "            \"response\": \"I apologize, but I'm currently experiencing technical difficulties and cannot process your request at this time. For immediate assistance, please contact our customer service team at 1-800-555-1234 (available 24/7) or visit your nearest branch location.\",\n",
    "            \"contact_info\": {\n",
    "                \"phone\": \"1-800-555-1234\",\n",
    "                \"hours\": \"24/7\",\n",
    "                \"alternative\": \"Visit nearest branch\"\n",
    "            }\n",
    "        },\n",
    "        \"product_question\": {\n",
    "            \"response\": \"I'm unable to access our product information systems at the moment. For detailed information about our financial products and services, please:\\\\n\\\\n1. Call our product specialists at 1-800-555-PROD (1-800-555-7763)\\\\n2. Visit www.example.com/products\\\\n3. Speak with a representative at any branch location\\\\n\\\\nOur team can provide personalized product recommendations based on your financial needs.\",\n",
    "            \"contact_info\": {\n",
    "                \"phone\": \"1-800-555-7763\",\n",
    "                \"website\": \"www.example.com/products\"\n",
    "            }\n",
    "        },\n",
    "        \"account_inquiry\": {\n",
    "            \"response\": \"For security reasons and to protect your personal information, I'm unable to process account inquiries at this time. Please use one of these secure alternatives:\\\\n\\\\n1. Log in to your online banking portal\\\\n2. Call our secure account services line at 1-800-555-ACCT (1-800-555-2228)\\\\n3. Visit a branch with valid photo identification\\\\n\\\\nFor urgent account matters, our phone representatives are available 24/7.\",\n",
    "            \"contact_info\": {\n",
    "                \"phone\": \"1-800-555-2228\",\n",
    "                \"online\": \"Online banking portal\",\n",
    "                \"hours\": \"24/7\"\n",
    "            }\n",
    "        },\n",
    "        \"compliance\": {\n",
    "            \"response\": \"I apologize, but I cannot provide regulatory or compliance information at this time. For accurate compliance-related inquiries:\\\\n\\\\n1. Contact our compliance department at compliance@example.com\\\\n2. Call our compliance hotline at 1-800-555-CMPL (1-800-555-2675)\\\\n3. Refer to official disclosures at www.example.com/disclosures\\\\n\\\\nAll financial products are subject to terms and conditions. Please consult official documentation.\",\n",
    "            \"contact_info\": {\n",
    "                \"email\": \"compliance@example.com\",\n",
    "                \"phone\": \"1-800-555-2675\",\n",
    "                \"website\": \"www.example.com/disclosures\"\n",
    "            }\n",
    "        },\n",
    "        \"personalized_outreach\": {\n",
    "            \"response\": \"Thank you for your interest. Unfortunately, I'm unable to provide personalized recommendations at this time. To discuss financial solutions tailored to your needs:\\\\n\\\\n1. Schedule an appointment with a financial advisor\\\\n2. Call 1-800-555-ADVS (1-800-555-2387)\\\\n3. Request a callback at www.example.com/contact\\\\n\\\\nOur advisors can help you achieve your financial goals with personalized guidance.\",\n",
    "            \"contact_info\": {\n",
    "                \"phone\": \"1-800-555-2387\",\n",
    "                \"website\": \"www.example.com/contact\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get appropriate response\n",
    "    default_response = responses[\"general\"]\n",
    "    response_data = responses.get(use_case, default_response)\n",
    "    \n",
    "    # Add standard disclaimer for financial services\n",
    "    disclaimer = \"\\\\n\\\\n---\\\\nThis is an automated response. Products and services are subject to terms and conditions. Not all products are available in all areas. Member FDIC. Equal Housing Lender.\"\n",
    "    \n",
    "    # Construct final response\n",
    "    final_response = response_data[\"response\"] + disclaimer\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps({\n",
    "            'response': final_response,\n",
    "            'model_used': 'DEGRADED_SERVICE',\n",
    "            'use_case': use_case,\n",
    "            'degradation_reason': reason,\n",
    "            'contact_info': response_data[\"contact_info\"],\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'message': 'Service degraded - using predefined response'\n",
    "        })\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Save degradation Lambda code\n",
    "with open(\"graceful_degradation_lambda.py\", \"w\") as f:\n",
    "    f.write(GRACEFUL_DEGRADATION_LAMBDA_CODE)\n",
    "\n",
    "print(\"✓ Graceful degradation Lambda code saved to: graceful_degradation_lambda.py\")\n",
    "print(\"\\nGraceful Degradation Features:\")\n",
    "print(\"  ✓ Predefined responses by use case\")\n",
    "print(\"  ✓ Regulation-compliant messaging\")\n",
    "print(\"  ✓ Contact information for each scenario\")\n",
    "print(\"  ✓ Standard FDIC and financial disclaimers\")\n",
    "print(\"  ✓ Marked as DEGRADED_SERVICE for monitoring\")\n",
    "print(\"  ✓ Always returns 200 status with helpful guidance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e6926",
   "metadata": {},
   "source": [
    "### Section 12: Setup Cross-Region Deployment with CloudFormation\n",
    "\n",
    "Create CloudFormation template for multi-region deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90dc5895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CloudFormation template saved to: cross_region_deployment.yaml\n",
      "\n",
      "To deploy to multiple regions:\n",
      "\n",
      "# Deploy to us-east-1 (primary):\n",
      "aws cloudformation deploy \\\n",
      "  --template-file cross_region_deployment.yaml \\\n",
      "  --stack-name ai-assistant-stack \\\n",
      "  --parameter-overrides Environment=prod \\\n",
      "  --region us-east-1 \\\n",
      "  --capabilities CAPABILITY_NAMED_IAM\n",
      "\n",
      "# Deploy to us-west-2 (secondary):\n",
      "aws cloudformation deploy \\\n",
      "  --template-file cross_region_deployment.yaml \\\n",
      "  --stack-name ai-assistant-stack \\\n",
      "  --parameter-overrides Environment=prod \\\n",
      "  --region us-west-2 \\\n",
      "  --capabilities CAPABILITY_NAMED_IAM\n"
     ]
    }
   ],
   "source": [
    "# CloudFormation template for cross-region deployment\n",
    "CLOUDFORMATION_TEMPLATE = '''\n",
    "AWSTemplateFormatVersion: '2010-09-09'\n",
    "Description: 'AI Assistant Cross-Region Deployment for High Availability'\n",
    "\n",
    "Parameters:\n",
    "  Environment:\n",
    "    Type: String\n",
    "    Default: prod\n",
    "    AllowedValues:\n",
    "      - dev\n",
    "      - staging\n",
    "      - prod\n",
    "    Description: Deployment environment\n",
    "  \n",
    "  AppName:\n",
    "    Type: String\n",
    "    Default: AIAssistantApp\n",
    "    Description: Application name for resource naming\n",
    "\n",
    "Resources:\n",
    "  # IAM Role for Lambda functions\n",
    "  LambdaExecutionRole:\n",
    "    Type: AWS::IAM::Role\n",
    "    Properties:\n",
    "      RoleName: !Sub \"${AppName}-Lambda-Role-${Environment}\"\n",
    "      AssumeRolePolicyDocument:\n",
    "        Version: '2012-10-17'\n",
    "        Statement:\n",
    "          - Effect: Allow\n",
    "            Principal:\n",
    "              Service: lambda.amazonaws.com\n",
    "            Action: 'sts:AssumeRole'\n",
    "      ManagedPolicyArns:\n",
    "        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "      Policies:\n",
    "        - PolicyName: BedrockAccess\n",
    "          PolicyDocument:\n",
    "            Version: '2012-10-17'\n",
    "            Statement:\n",
    "              - Effect: Allow\n",
    "                Action:\n",
    "                  - 'bedrock:InvokeModel'\n",
    "                  - 'bedrock-runtime:InvokeModel'\n",
    "                Resource: '*'\n",
    "        - PolicyName: AppConfigAccess\n",
    "          PolicyDocument:\n",
    "            Version: '2012-10-17'\n",
    "            Statement:\n",
    "              - Effect: Allow\n",
    "                Action:\n",
    "                  - 'appconfig:GetConfiguration'\n",
    "                  - 'appconfig:StartConfigurationSession'\n",
    "                  - 'appconfig:GetLatestConfiguration'\n",
    "                Resource: '*'\n",
    "        - PolicyName: DynamoDBAccess\n",
    "          PolicyDocument:\n",
    "            Version: '2012-10-17'\n",
    "            Statement:\n",
    "              - Effect: Allow\n",
    "                Action:\n",
    "                  - 'dynamodb:PutItem'\n",
    "                  - 'dynamodb:GetItem'\n",
    "                  - 'dynamodb:UpdateItem'\n",
    "                Resource: !GetAtt CircuitBreakerTable.Arn\n",
    "\n",
    "  # DynamoDB table for circuit breaker state\n",
    "  CircuitBreakerTable:\n",
    "    Type: AWS::DynamoDB::Table\n",
    "    Properties:\n",
    "      TableName: !Sub \"${AppName}-CircuitBreaker-${Environment}\"\n",
    "      BillingMode: PAY_PER_REQUEST\n",
    "      AttributeDefinitions:\n",
    "        - AttributeName: circuitId\n",
    "          AttributeType: S\n",
    "      KeySchema:\n",
    "        - AttributeName: circuitId\n",
    "          KeyType: HASH\n",
    "      StreamSpecification:\n",
    "        StreamViewType: NEW_AND_OLD_IMAGES\n",
    "      PointInTimeRecoverySpecification:\n",
    "        PointInTimeRecoveryEnabled: true\n",
    "\n",
    "  # Model Abstraction Lambda\n",
    "  ModelAbstractionLambda:\n",
    "    Type: AWS::Lambda::Function\n",
    "    Properties:\n",
    "      FunctionName: !Sub \"${AppName}-ModelAbstraction-${Environment}\"\n",
    "      Runtime: python3.11\n",
    "      Handler: index.lambda_handler\n",
    "      Role: !GetAtt LambdaExecutionRole.Arn\n",
    "      Timeout: 30\n",
    "      MemorySize: 512\n",
    "      Environment:\n",
    "        Variables:\n",
    "          APP_NAME: !Ref AppName\n",
    "          ENVIRONMENT: !Ref Environment\n",
    "      Code:\n",
    "        ZipFile: |\n",
    "          # Code from model_abstraction_lambda.py\n",
    "          import json\n",
    "          def lambda_handler(event, context):\n",
    "              return {'statusCode': 200, 'body': json.dumps('Placeholder')}\n",
    "\n",
    "  # Fallback Model Lambda\n",
    "  FallbackModelLambda:\n",
    "    Type: AWS::Lambda::Function\n",
    "    Properties:\n",
    "      FunctionName: !Sub \"${AppName}-FallbackModel-${Environment}\"\n",
    "      Runtime: python3.11\n",
    "      Handler: index.lambda_handler\n",
    "      Role: !GetAtt LambdaExecutionRole.Arn\n",
    "      Timeout: 20\n",
    "      MemorySize: 256\n",
    "      Code:\n",
    "        ZipFile: |\n",
    "          # Code from fallback_model_lambda.py\n",
    "          import json\n",
    "          def lambda_handler(event, context):\n",
    "              return {'statusCode': 200, 'body': json.dumps('Fallback')}\n",
    "\n",
    "  # Graceful Degradation Lambda\n",
    "  GracefulDegradationLambda:\n",
    "    Type: AWS::Lambda::Function\n",
    "    Properties:\n",
    "      FunctionName: !Sub \"${AppName}-GracefulDegradation-${Environment}\"\n",
    "      Runtime: python3.11\n",
    "      Handler: index.lambda_handler\n",
    "      Role: !GetAtt LambdaExecutionRole.Arn\n",
    "      Timeout: 10\n",
    "      MemorySize: 128\n",
    "      Code:\n",
    "        ZipFile: |\n",
    "          # Code from graceful_degradation_lambda.py\n",
    "          import json\n",
    "          def lambda_handler(event, context):\n",
    "              return {'statusCode': 200, 'body': json.dumps('Degraded')}\n",
    "\n",
    "  # API Gateway\n",
    "  ApiGateway:\n",
    "    Type: AWS::ApiGateway::RestApi\n",
    "    Properties:\n",
    "      Name: !Sub \"${AppName}-API-${Environment}\"\n",
    "      Description: API for AI Assistant\n",
    "      EndpointConfiguration:\n",
    "        Types:\n",
    "          - REGIONAL\n",
    "\n",
    "  # API Gateway Resource\n",
    "  GenerateResource:\n",
    "    Type: AWS::ApiGateway::Resource\n",
    "    Properties:\n",
    "      RestApiId: !Ref ApiGateway\n",
    "      ParentId: !GetAtt ApiGateway.RootResourceId\n",
    "      PathPart: generate\n",
    "\n",
    "  # API Gateway Method\n",
    "  GenerateMethod:\n",
    "    Type: AWS::ApiGateway::Method\n",
    "    Properties:\n",
    "      RestApiId: !Ref ApiGateway\n",
    "      ResourceId: !Ref GenerateResource\n",
    "      HttpMethod: POST\n",
    "      AuthorizationType: NONE\n",
    "      Integration:\n",
    "        Type: AWS_PROXY\n",
    "        IntegrationHttpMethod: POST\n",
    "        Uri: !Sub \"arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${ModelAbstractionLambda.Arn}/invocations\"\n",
    "\n",
    "  # Lambda Permission for API Gateway\n",
    "  ApiGatewayInvokePermission:\n",
    "    Type: AWS::Lambda::Permission\n",
    "    Properties:\n",
    "      FunctionName: !Ref ModelAbstractionLambda\n",
    "      Action: lambda:InvokeFunction\n",
    "      Principal: apigateway.amazonaws.com\n",
    "      SourceArn: !Sub \"arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${ApiGateway}/*\"\n",
    "\n",
    "  # API Gateway Deployment\n",
    "  ApiDeployment:\n",
    "    Type: AWS::ApiGateway::Deployment\n",
    "    DependsOn: GenerateMethod\n",
    "    Properties:\n",
    "      RestApiId: !Ref ApiGateway\n",
    "      StageName: !Ref Environment\n",
    "\n",
    "  # CloudWatch Log Group\n",
    "  ApiLogGroup:\n",
    "    Type: AWS::Logs::LogGroup\n",
    "    Properties:\n",
    "      LogGroupName: !Sub \"/aws/apigateway/${AppName}-${Environment}\"\n",
    "      RetentionInDays: 30\n",
    "\n",
    "Outputs:\n",
    "  ApiEndpoint:\n",
    "    Description: API Gateway endpoint URL\n",
    "    Value: !Sub \"https://${ApiGateway}.execute-api.${AWS::Region}.amazonaws.com/${Environment}/generate\"\n",
    "    Export:\n",
    "      Name: !Sub \"${AppName}-ApiEndpoint-${Environment}\"\n",
    "  \n",
    "  ModelAbstractionLambdaArn:\n",
    "    Description: Model Abstraction Lambda ARN\n",
    "    Value: !GetAtt ModelAbstractionLambda.Arn\n",
    "    Export:\n",
    "      Name: !Sub \"${AppName}-ModelAbstractionLambda-${Environment}\"\n",
    "  \n",
    "  FallbackModelLambdaArn:\n",
    "    Description: Fallback Model Lambda ARN\n",
    "    Value: !GetAtt FallbackModelLambda.Arn\n",
    "    Export:\n",
    "      Name: !Sub \"${AppName}-FallbackModelLambda-${Environment}\"\n",
    "  \n",
    "  GracefulDegradationLambdaArn:\n",
    "    Description: Graceful Degradation Lambda ARN\n",
    "    Value: !GetAtt GracefulDegradationLambda.Arn\n",
    "    Export:\n",
    "      Name: !Sub \"${AppName}-GracefulDegradationLambda-${Environment}\"\n",
    "  \n",
    "  CircuitBreakerTableName:\n",
    "    Description: DynamoDB Circuit Breaker Table Name\n",
    "    Value: !Ref CircuitBreakerTable\n",
    "    Export:\n",
    "      Name: !Sub \"${AppName}-CircuitBreakerTable-${Environment}\"\n",
    "'''\n",
    "\n",
    "# Save CloudFormation template\n",
    "with open(\"cross_region_deployment.yaml\", \"w\") as f:\n",
    "    f.write(CLOUDFORMATION_TEMPLATE)\n",
    "\n",
    "print(\"✓ CloudFormation template saved to: cross_region_deployment.yaml\")\n",
    "print(\"\\nTo deploy to multiple regions:\")\n",
    "print(f\"\\n# Deploy to {PRIMARY_REGION} (primary):\")\n",
    "print(f\"aws cloudformation deploy \\\\\")\n",
    "print(f\"  --template-file cross_region_deployment.yaml \\\\\")\n",
    "print(f\"  --stack-name ai-assistant-stack \\\\\")\n",
    "print(f\"  --parameter-overrides Environment={ENVIRONMENT} \\\\\")\n",
    "print(f\"  --region {PRIMARY_REGION} \\\\\")\n",
    "print(f\"  --capabilities CAPABILITY_NAMED_IAM\")\n",
    "print(f\"\\n# Deploy to {SECONDARY_REGION} (secondary):\")\n",
    "print(f\"aws cloudformation deploy \\\\\")\n",
    "print(f\"  --template-file cross_region_deployment.yaml \\\\\")\n",
    "print(f\"  --stack-name ai-assistant-stack \\\\\")\n",
    "print(f\"  --parameter-overrides Environment={ENVIRONMENT} \\\\\")\n",
    "print(f\"  --region {SECONDARY_REGION} \\\\\")\n",
    "print(f\"  --capabilities CAPABILITY_NAMED_IAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae4e643",
   "metadata": {},
   "source": [
    "### Section 13: Configure Route 53 Failover Routing\n",
    "\n",
    "Set up DNS-based failover for automatic traffic redirection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab401a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route 53 Failover Configuration\n",
      "================================================================================\n",
      "To configure failover:\n",
      "1. Ensure you have a registered domain name\n",
      "2. Deploy API Gateway to both regions\n",
      "3. Run the configuration function:\n",
      "\n",
      "Example:\n",
      "configure_route53_failover(\n",
      "    primary_api_id='qqskzpxhgb',\n",
      "    secondary_api_id='SECONDARY_API_ID',\n",
      "    domain_name='yourdomain.com'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def configure_route53_failover(primary_api_id, secondary_api_id, domain_name):\n",
    "    \"\"\"\n",
    "    Configure Route 53 DNS failover for high availability.\n",
    "    \n",
    "    Args:\n",
    "        primary_api_id: API Gateway ID in primary region\n",
    "        secondary_api_id: API Gateway ID in secondary region\n",
    "        domain_name: Root domain name (e.g., example.com)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # API Gateway Hosted Zone IDs (Regional)\n",
    "        # https://docs.aws.amazon.com/general/latest/gr/apigateway.html\n",
    "        API_GATEWAY_ZONES = {\n",
    "            'us-east-1': 'Z1UJRXOUMOOFQ8',\n",
    "            'us-west-2': 'Z2OJLYMUO9EFXC',\n",
    "            'eu-west-1': 'ZLY8HYME6SFDD',\n",
    "            # Add others as needed\n",
    "        }\n",
    "        \n",
    "        timestamp = str(int(time.time()))\n",
    "        caller_ref = f\"health-check-{timestamp}\"\n",
    "        \n",
    "        # 1. Create Health Check for Primary Region\n",
    "        print(f\"Creating health check for {PRIMARY_REGION}...\")\n",
    "        fqdn = f\"{primary_api_id}.execute-api.{PRIMARY_REGION}.amazonaws.com\"\n",
    "        \n",
    "        hc_response = route53_client.create_health_check(\n",
    "            CallerReference=caller_ref,\n",
    "            HealthCheckConfig={\n",
    "                'Port': 443,\n",
    "                'Type': 'HTTPS',\n",
    "                'ResourcePath': '/prod/generate',\n",
    "                'FullyQualifiedDomainName': fqdn,\n",
    "                'RequestInterval': 30,\n",
    "                'FailureThreshold': 3,\n",
    "                'MeasureLatency': True,\n",
    "                'Inverted': False,\n",
    "                'Disabled': False,\n",
    "                'EnableSNI': True\n",
    "            }\n",
    "        )\n",
    "        health_check_id = hc_response['HealthCheck']['Id']\n",
    "        print(f\"✓ Created health check: {health_check_id}\")\n",
    "        \n",
    "        # 2. Get or Create Hosted Zone\n",
    "        print(f\"Checking hosted zone for {domain_name}...\")\n",
    "        hosted_zone_id = None\n",
    "        \n",
    "        # List zones to find existing\n",
    "        zones = route53_client.list_hosted_zones_by_name(DNSName=domain_name)\n",
    "        # Check if we found an exact match or parent\n",
    "        for zone in zones['HostedZones']:\n",
    "            if zone['Name'].rstrip('.') == domain_name.rstrip('.'):\n",
    "                hosted_zone_id = zone['Id']\n",
    "                print(f\"✓ Found existing hosted zone: {hosted_zone_id}\")\n",
    "                break\n",
    "        \n",
    "        if not hosted_zone_id:\n",
    "            # Create new zone\n",
    "            print(\"Creating new hosted zone...\")\n",
    "            hz_response = route53_client.create_hosted_zone(\n",
    "                Name=domain_name,\n",
    "                CallerReference=f\"zone-{timestamp}\",\n",
    "                HostedZoneConfig={'Comment': 'AI Assistant Failover'}\n",
    "            )\n",
    "            hosted_zone_id = hz_response['HostedZone']['Id']\n",
    "            print(f\"✓ Created hosted zone: {hosted_zone_id}\")\n",
    "            \n",
    "        # 3. Create Failover Records\n",
    "        print(\"Creating failover DNS records...\")\n",
    "        \n",
    "        subdomain = f\"ai-assistant.{domain_name}\"\n",
    "        \n",
    "        change_batch = {\n",
    "            'Changes': [\n",
    "                {\n",
    "                    'Action': 'UPSERT',\n",
    "                    'ResourceRecordSet': {\n",
    "                        'Name': subdomain,\n",
    "                        'Type': 'A',\n",
    "                        'SetIdentifier': 'Primary',\n",
    "                        'Failover': 'PRIMARY',\n",
    "                        'HealthCheckId': health_check_id,\n",
    "                        'AliasTarget': {\n",
    "                            'HostedZoneId': API_GATEWAY_ZONES.get(PRIMARY_REGION),\n",
    "                            'DNSName': f\"{primary_api_id}.execute-api.{PRIMARY_REGION}.amazonaws.com\",\n",
    "                            'EvaluateTargetHealth': True\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'Action': 'UPSERT',\n",
    "                    'ResourceRecordSet': {\n",
    "                        'Name': subdomain,\n",
    "                        'Type': 'A',\n",
    "                        'SetIdentifier': 'Secondary',\n",
    "                        'Failover': 'SECONDARY',\n",
    "                        'AliasTarget': {\n",
    "                            'HostedZoneId': API_GATEWAY_ZONES.get(SECONDARY_REGION),\n",
    "                            'DNSName': f\"{secondary_api_id}.execute-api.{SECONDARY_REGION}.amazonaws.com\",\n",
    "                            'EvaluateTargetHealth': True\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        route53_client.change_resource_record_sets(\n",
    "            HostedZoneId=hosted_zone_id,\n",
    "            ChangeBatch=change_batch\n",
    "        )\n",
    "        print(\"✓ Created failover DNS records\")\n",
    "        \n",
    "        print(f\"\\nFailover Setup Complete!\")\n",
    "        print(f\"Primary: {PRIMARY_REGION} (Health Check: {health_check_id})\")\n",
    "        print(f\"Secondary: {SECONDARY_REGION}\")\n",
    "        print(f\"Global Endpoint: https://{subdomain}/prod/generate\")\n",
    "        \n",
    "        return {\n",
    "            \"health_check_id\": health_check_id,\n",
    "            \"hosted_zone_id\": hosted_zone_id,\n",
    "            \"domain_name\": subdomain\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error setting up Route 53: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "print(\"Route 53 Failover Configuration\")\n",
    "print(\"=\"*80)\n",
    "print(\"To configure failover:\")\n",
    "print(\"1. Ensure you have a registered domain name\")\n",
    "print(\"2. Deploy API Gateway to both regions\")\n",
    "print(\"3. Run the configuration function:\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"configure_route53_failover(\")\n",
    "print(f\"    primary_api_id='{api_info['api_id'] if 'api_info' in locals() and api_info else 'PRIMARY_API_ID'}',\")\n",
    "print(\"    secondary_api_id='SECONDARY_API_ID',\")\n",
    "print(\"    domain_name='yourdomain.com'\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37498d",
   "metadata": {},
   "source": [
    "## Part 4: Model customization and lifecycle management\n",
    "\n",
    "### Step 1: Fine-tune a model with SageMaker\n",
    "\n",
    "1. Prepare a fine-tuning dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee60ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created financial_qa_dataset.csv\n",
      "✓ Created train.py training script\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Create a financial Q&A dataset\n",
    "data = [\n",
    "    {\"question\": \"What is a 401(k)?\", \"answer\": \"A 401(k) is a tax-advantaged retirement savings plan offered by employers.\"},\n",
    "    {\"question\": \"How does compound interest work?\", \"answer\": \"Compound interest is when you earn interest on both the money you've saved and the interest you earn.\"},\n",
    "    {\"question\": \"What is an ETF?\", \"answer\": \"An ETF (Exchange Traded Fund) is a type of security that tracks an index, sector, commodity, or other asset, but which can be purchased or sold on a stock exchange the same way a regular stock can.\"},\n",
    "    {\"question\": \"What is a dividend?\", \"answer\": \"A dividend is a distribution of some of a company's earnings to a class of its shareholders, as determined by the company's board of directors.\"},\n",
    "    {\"question\": \"What is a credit score?\", \"answer\": \"A credit score is a numerical expression based on a level analysis of a person's credit files, to represent the creditworthiness of an individual.\"}\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV for SageMaker training\n",
    "df.to_csv(\"financial_qa_dataset.csv\", index=False)\n",
    "print(\"✓ Created financial_qa_dataset.csv\")\n",
    "\n",
    "# Create SageMaker training script\n",
    "with open(\"train.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--training-dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAINING\"))\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    \n",
    "    # Load dataset\n",
    "    data_path = os.path.join(args.training_dir, \"financial_qa_dataset.csv\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Prepare dataset\n",
    "    def format_instruction(row):\n",
    "        return f\"Question: {row['question']}\\\\nAnswer: {row['answer']}\"\n",
    "    \n",
    "    df[\"text\"] = df.apply(format_instruction, axis=1)\n",
    "    dataset = Dataset.from_pandas(df[[\"text\"]])\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model_name = \"distilgpt2\"  # Use a smaller model for example purposes\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    # Tokenize dataset\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=args.model_dir,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save model\n",
    "    trainer.save_model(args.model_dir)\n",
    "    tokenizer.save_pretrained(args.model_dir)\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Created train.py training script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f03664",
   "metadata": {},
   "source": [
    "2. Launch SageMaker Training Job:\n",
    "\n",
    "Upload the dataset to S3 and define the SageMaker Estimator to run the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57a30262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\DELL\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\DELL\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\DELL\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\DELL\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name exerciseuser to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get execution role from environment. Searching IAM roles...\n",
      "Found SageMaker execution role: arn:aws:iam::091366569168:role/service-role/AmazonSageMaker-ExecutionRole-20230424T121108\n",
      "✓ Using role: arn:aws:iam::091366569168:role/service-role/AmazonSageMaker-ExecutionRole-20230424T121108\n",
      "✓ Uploading data to bucket: cert-genai-dev, prefix: bonus_1_2/data\n",
      "Found SageMaker execution role: arn:aws:iam::091366569168:role/service-role/AmazonSageMaker-ExecutionRole-20230424T121108\n",
      "✓ Using role: arn:aws:iam::091366569168:role/service-role/AmazonSageMaker-ExecutionRole-20230424T121108\n",
      "✓ Uploading data to bucket: cert-genai-dev, prefix: bonus_1_2/data\n",
      "✓ Dataset uploaded to: s3://cert-genai-dev/bonus_1_2/data/financial_qa_dataset.csv\n",
      "\n",
      "================================================================================\n",
      "SAGEMAKER FINE-TUNING SETUP COMPLETE\n",
      "================================================================================\n",
      "\n",
      "📋 Summary:\n",
      "   • Training Data: s3://cert-genai-dev/bonus_1_2/data/financial_qa_dataset.csv\n",
      "   • Training Script: train.py\n",
      "   • IAM Role: AmazonSageMaker-ExecutionRole-20230424T121108\n",
      "\n",
      "⚠️  Note: Due to SDK version constraints and instance quota limits,\n",
      "   actual training job execution requires either:\n",
      "   1. GPU instance quota (ml.g4dn.xlarge)\n",
      "   2. Upgraded SageMaker SDK (pip install -U sagemaker)\n",
      "\n",
      "📝 To run the training job manually:\n",
      "\n",
      "   1. Request GPU quota increase via AWS Service Quotas\n",
      "   2. Use GPU-compatible configuration:\n",
      "\n",
      "   huggingface_estimator = HuggingFace(\n",
      "       entry_point=\"train.py\",\n",
      "       source_dir=\".\",\n",
      "       instance_type=\"ml.g4dn.xlarge\",  # GPU instance\n",
      "       instance_count=1,\n",
      "       role=role,\n",
      "       transformers_version=\"4.17.0\",\n",
      "       pytorch_version=\"1.10.2\",\n",
      "       py_version=\"py38\",\n",
      "       hyperparameters={\n",
      "           \"epochs\": 3,\n",
      "           \"train_batch_size\": 4,\n",
      "           \"model_dir\": \"/opt/ml/model\"\n",
      "       }\n",
      "   )\n",
      "\n",
      "   huggingface_estimator.fit({'training': input_data_uri})\n",
      "    \n",
      "\n",
      "✓ All preparation steps completed successfully!\n",
      "✓ Training data uploaded and ready for fine-tuning\n",
      "✓ Dataset uploaded to: s3://cert-genai-dev/bonus_1_2/data/financial_qa_dataset.csv\n",
      "\n",
      "================================================================================\n",
      "SAGEMAKER FINE-TUNING SETUP COMPLETE\n",
      "================================================================================\n",
      "\n",
      "📋 Summary:\n",
      "   • Training Data: s3://cert-genai-dev/bonus_1_2/data/financial_qa_dataset.csv\n",
      "   • Training Script: train.py\n",
      "   • IAM Role: AmazonSageMaker-ExecutionRole-20230424T121108\n",
      "\n",
      "⚠️  Note: Due to SDK version constraints and instance quota limits,\n",
      "   actual training job execution requires either:\n",
      "   1. GPU instance quota (ml.g4dn.xlarge)\n",
      "   2. Upgraded SageMaker SDK (pip install -U sagemaker)\n",
      "\n",
      "📝 To run the training job manually:\n",
      "\n",
      "   1. Request GPU quota increase via AWS Service Quotas\n",
      "   2. Use GPU-compatible configuration:\n",
      "\n",
      "   huggingface_estimator = HuggingFace(\n",
      "       entry_point=\"train.py\",\n",
      "       source_dir=\".\",\n",
      "       instance_type=\"ml.g4dn.xlarge\",  # GPU instance\n",
      "       instance_count=1,\n",
      "       role=role,\n",
      "       transformers_version=\"4.17.0\",\n",
      "       pytorch_version=\"1.10.2\",\n",
      "       py_version=\"py38\",\n",
      "       hyperparameters={\n",
      "           \"epochs\": 3,\n",
      "           \"train_batch_size\": 4,\n",
      "           \"model_dir\": \"/opt/ml/model\"\n",
      "       }\n",
      "   )\n",
      "\n",
      "   huggingface_estimator.fit({'training': input_data_uri})\n",
      "    \n",
      "\n",
      "✓ All preparation steps completed successfully!\n",
      "✓ Training data uploaded and ready for fine-tuning\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import boto3\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Try to get role\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    print(\"Could not get execution role from environment. Searching IAM roles...\")\n",
    "    try:\n",
    "        iam = boto3.client('iam')\n",
    "        roles = iam.list_roles()\n",
    "        # Look for a role with 'SageMaker' and 'Execution' in the name\n",
    "        sm_roles = [r['Arn'] for r in roles['Roles'] if 'SageMaker' in r['RoleName'] and 'Execution' in r['RoleName']]\n",
    "        if sm_roles:\n",
    "            role = sm_roles[0]\n",
    "            print(f\"Found SageMaker execution role: {role}\")\n",
    "        else:\n",
    "            # Fallback to any SageMaker role\n",
    "            sm_roles = [r['Arn'] for r in roles['Roles'] if 'SageMaker' in r['RoleName']]\n",
    "            if sm_roles:\n",
    "                role = sm_roles[0]\n",
    "                print(f\"Found SageMaker role: {role}\")\n",
    "            else:\n",
    "                print(\"No SageMaker role found. Please create one and specify 'role' manually.\")\n",
    "                role = None\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching roles: {e}\")\n",
    "        role = None\n",
    "\n",
    "if role:\n",
    "    print(f\"✓ Using role: {role}\")\n",
    "    \n",
    "    # Parse S3 bucket and prefix\n",
    "    if \"/\" in S3_BUCKET:\n",
    "        bucket_name = S3_BUCKET.split(\"/\")[0]\n",
    "        prefix = \"/\".join(S3_BUCKET.split(\"/\")[1:])\n",
    "        if prefix.endswith(\"/\"):\n",
    "            prefix = prefix[:-1]\n",
    "    else:\n",
    "        bucket_name = S3_BUCKET\n",
    "        prefix = \"financial-qa\"\n",
    "        \n",
    "    print(f\"✓ Uploading data to bucket: {bucket_name}, prefix: {prefix}/data\")\n",
    "\n",
    "    # Upload dataset to S3\n",
    "    input_data_uri = sess.upload_data(\n",
    "        path=\"financial_qa_dataset.csv\",\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{prefix}/data\"\n",
    "    )\n",
    "    print(f\"✓ Dataset uploaded to: {input_data_uri}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAGEMAKER FINE-TUNING SETUP COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n📋 Summary:\")\n",
    "    print(f\"   • Training Data: {input_data_uri}\")\n",
    "    print(f\"   • Training Script: train.py\")\n",
    "    print(f\"   • IAM Role: {role.split('/')[-1]}\")\n",
    "    \n",
    "    print(\"\\n⚠️  Note: Due to SDK version constraints and instance quota limits,\")\n",
    "    print(\"   actual training job execution requires either:\")\n",
    "    print(\"   1. GPU instance quota (ml.g4dn.xlarge)\")\n",
    "    print(\"   2. Upgraded SageMaker SDK (pip install -U sagemaker)\")\n",
    "    \n",
    "    print(\"\\n📝 To run the training job manually:\")\n",
    "    print(\"\\n   1. Request GPU quota increase via AWS Service Quotas\")\n",
    "    print(\"   2. Use GPU-compatible configuration:\")\n",
    "    \n",
    "    print(\"\"\"\n",
    "   huggingface_estimator = HuggingFace(\n",
    "       entry_point=\"train.py\",\n",
    "       source_dir=\".\",\n",
    "       instance_type=\"ml.g4dn.xlarge\",  # GPU instance\n",
    "       instance_count=1,\n",
    "       role=role,\n",
    "       transformers_version=\"4.17.0\",\n",
    "       pytorch_version=\"1.10.2\",\n",
    "       py_version=\"py38\",\n",
    "       hyperparameters={\n",
    "           \"epochs\": 3,\n",
    "           \"train_batch_size\": 4,\n",
    "           \"model_dir\": \"/opt/ml/model\"\n",
    "       }\n",
    "   )\n",
    "   \n",
    "   huggingface_estimator.fit({'training': input_data_uri})\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n✓ All preparation steps completed successfully!\")\n",
    "    print(\"✓ Training data uploaded and ready for fine-tuning\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Skipping SageMaker setup due to missing role.\")\n",
    "    print(\"   Please create a SageMaker execution role in IAM console.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a814d4b1",
   "metadata": {},
   "source": [
    "### Step 2: Deploy the Fine-tuned Model\n",
    "\n",
    "Once training is complete, deploy the model to a SageMaker endpoint for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beab050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_fine_tuned_model(training_job_name=None):\n",
    "    \"\"\"\n",
    "    Deploy a fine-tuned model to a SageMaker endpoint.\n",
    "    \n",
    "    Args:\n",
    "        training_job_name: Name of the completed training job\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with endpoint information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If training job name provided, get the model artifacts\n",
    "        if training_job_name:\n",
    "            print(f\"Retrieving model artifacts from training job: {training_job_name}\")\n",
    "            \n",
    "            # Describe training job to get model artifacts\n",
    "            training_job = sagemaker_client.describe_training_job(\n",
    "                TrainingJobName=training_job_name\n",
    "            )\n",
    "            \n",
    "            model_data_url = training_job['ModelArtifacts']['S3ModelArtifacts']\n",
    "            print(f\"✓ Model artifacts: {model_data_url}\")\n",
    "            \n",
    "            # Create model\n",
    "            model_name = f\"financial-qa-model-{int(time.time())}\"\n",
    "            print(f\"Creating model: {model_name}\")\n",
    "            \n",
    "            # Get execution role\n",
    "            try:\n",
    "                role = sagemaker.get_execution_role()\n",
    "            except:\n",
    "                iam = boto3.client('iam')\n",
    "                roles = iam.list_roles()\n",
    "                sm_roles = [r['Arn'] for r in roles['Roles'] if 'SageMaker' in r['RoleName']]\n",
    "                role = sm_roles[0] if sm_roles else None\n",
    "            \n",
    "            if not role:\n",
    "                print(\"❌ No SageMaker role found\")\n",
    "                return None\n",
    "            \n",
    "            # Create SageMaker model\n",
    "            create_model_response = sagemaker_client.create_model(\n",
    "                ModelName=model_name,\n",
    "                PrimaryContainer={\n",
    "                    'Image': training_job['AlgorithmSpecification']['TrainingImage'],\n",
    "                    'ModelDataUrl': model_data_url,\n",
    "                    'Environment': {\n",
    "                        'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "                        'SAGEMAKER_SUBMIT_DIRECTORY': model_data_url,\n",
    "                        'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
    "                        'SAGEMAKER_REGION': PRIMARY_REGION\n",
    "                    }\n",
    "                },\n",
    "                ExecutionRoleArn=role\n",
    "            )\n",
    "            print(f\"✓ Model created: {model_name}\")\n",
    "            \n",
    "            # Create endpoint configuration\n",
    "            endpoint_config_name = f\"{model_name}-config\"\n",
    "            print(f\"Creating endpoint configuration: {endpoint_config_name}\")\n",
    "            \n",
    "            endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "                EndpointConfigName=endpoint_config_name,\n",
    "                ProductionVariants=[{\n",
    "                    'InstanceType': 'ml.m5.xlarge',\n",
    "                    'InitialInstanceCount': 1,\n",
    "                    'ModelName': model_name,\n",
    "                    'VariantName': 'AllTraffic'\n",
    "                }]\n",
    "            )\n",
    "            print(f\"✓ Endpoint configuration created\")\n",
    "            \n",
    "            # Create endpoint\n",
    "            endpoint_name = f\"financial-qa-endpoint-{int(time.time())}\"\n",
    "            print(f\"Creating endpoint: {endpoint_name}\")\n",
    "            print(\"⏳ This may take 5-10 minutes...\")\n",
    "            \n",
    "            endpoint_response = sagemaker_client.create_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                EndpointConfigName=endpoint_config_name\n",
    "            )\n",
    "            \n",
    "            # Wait for endpoint to be in service\n",
    "            print(\"Waiting for endpoint to be in service...\")\n",
    "            waiter = sagemaker_client.get_waiter('endpoint_in_service')\n",
    "            waiter.wait(EndpointName=endpoint_name)\n",
    "            \n",
    "            print(f\"\\n✓ Endpoint deployed successfully!\")\n",
    "            \n",
    "            return {\n",
    "                \"endpoint_name\": endpoint_name,\n",
    "                \"endpoint_config_name\": endpoint_config_name,\n",
    "                \"model_name\": model_name,\n",
    "                \"status\": \"InService\"\n",
    "            }\n",
    "        else:\n",
    "            print(\"⚠️  No training job name provided.\")\n",
    "            print(\"\\nTo deploy a model:\")\n",
    "            print(\"1. Complete a SageMaker training job\")\n",
    "            print(\"2. Note the training job name\")\n",
    "            print(\"3. Run: deploy_fine_tuned_model('your-training-job-name')\")\n",
    "            \n",
    "            print(\"\\n📝 Deployment Process:\")\n",
    "            print(\"   • Creates SageMaker Model from training artifacts\")\n",
    "            print(\"   • Creates Endpoint Configuration with instance type\")\n",
    "            print(\"   • Deploys to real-time inference endpoint\")\n",
    "            print(\"   • Waits for endpoint to be InService (5-10 minutes)\")\n",
    "            \n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error deploying model: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL DEPLOYMENT\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✓ Deployment function ready\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  endpoint_info = deploy_fine_tuned_model('your-training-job-name')\")\n",
    "print(\"\\nOr call without parameters to see instructions:\")\n",
    "print(\"  deploy_fine_tuned_model()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e626659",
   "metadata": {},
   "source": [
    "### Step 3: Test the Deployed Model\n",
    "\n",
    "Invoke the endpoint to test the fine-tuned model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bdc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sagemaker_endpoint(endpoint_name, test_questions=None):\n",
    "    \"\"\"\n",
    "    Test a deployed SageMaker endpoint with financial questions.\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name: Name of the deployed endpoint\n",
    "        test_questions: List of test questions (optional)\n",
    "        \n",
    "    Returns:\n",
    "        List of test results with predictions\n",
    "    \"\"\"\n",
    "    if not test_questions:\n",
    "        test_questions = [\n",
    "            \"What is a 401(k)?\",\n",
    "            \"How does compound interest work?\",\n",
    "            \"What is an ETF?\",\n",
    "            \"What is a credit score?\"\n",
    "        ]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"TESTING ENDPOINT: {endpoint_name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n[Test {i}/{len(test_questions)}] Question: {question}\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare payload\n",
    "            payload = {\n",
    "                \"inputs\": f\"Question: {question}\\nAnswer:\",\n",
    "                \"parameters\": {\n",
    "                    \"max_new_tokens\": 100,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"top_p\": 0.9\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Invoke endpoint\n",
    "            response = sagemaker_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType='application/json',\n",
    "                Body=json.dumps(payload)\n",
    "            )\n",
    "            \n",
    "            # Parse response\n",
    "            result = json.loads(response['Body'].read().decode())\n",
    "            \n",
    "            # Extract generated text\n",
    "            if isinstance(result, list) and len(result) > 0:\n",
    "                answer = result[0].get('generated_text', 'No answer generated')\n",
    "            elif isinstance(result, dict):\n",
    "                answer = result.get('generated_text', result.get('predictions', 'No answer generated'))\n",
    "            else:\n",
    "                answer = str(result)\n",
    "            \n",
    "            print(f\"✓ Answer: {answer[:200]}...\")\n",
    "            \n",
    "            results.append({\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"success\": True,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "            results.append({\n",
    "                \"question\": question,\n",
    "                \"answer\": None,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    print(f\"Successful: {successful}/{len(results)}\")\n",
    "    print(f\"Failed: {len(results) - successful}/{len(results)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "print(\"✓ Endpoint testing function ready\")\n",
    "print(\"\\nTo test an endpoint:\")\n",
    "print(\"  results = test_sagemaker_endpoint('your-endpoint-name')\")\n",
    "print(\"\\nWith custom questions:\")\n",
    "print(\"  results = test_sagemaker_endpoint('endpoint-name', ['What is a dividend?', 'Explain mutual funds'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44caa3",
   "metadata": {},
   "source": [
    "### Step 4: Implement Model Monitoring with CloudWatch\n",
    "\n",
    "Set up CloudWatch monitoring to track model performance and detect drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7dd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model_monitoring(endpoint_name):\n",
    "    \"\"\"\n",
    "    Configure CloudWatch monitoring and alarms for a SageMaker endpoint.\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name: Name of the endpoint to monitor\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with monitoring configuration details\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"=\"*80)\n",
    "        print(f\"SETTING UP MONITORING FOR: {endpoint_name}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # 1. Create CloudWatch Alarms\n",
    "        alarms_created = []\n",
    "        \n",
    "        # High latency alarm\n",
    "        print(\"\\n[1/4] Creating high latency alarm...\")\n",
    "        alarm_name_latency = f\"{endpoint_name}-high-latency\"\n",
    "        \n",
    "        cloudwatch_client.put_metric_alarm(\n",
    "            AlarmName=alarm_name_latency,\n",
    "            ComparisonOperator='GreaterThanThreshold',\n",
    "            EvaluationPeriods=2,\n",
    "            MetricName='ModelLatency',\n",
    "            Namespace='AWS/SageMaker',\n",
    "            Period=300,  # 5 minutes\n",
    "            Statistic='Average',\n",
    "            Threshold=5000.0,  # 5 seconds\n",
    "            ActionsEnabled=False,  # Set to True with SNS topic for notifications\n",
    "            AlarmDescription=f'Alarm when model latency exceeds 5 seconds',\n",
    "            Dimensions=[\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName', 'Value': 'AllTraffic'}\n",
    "            ]\n",
    "        )\n",
    "        print(f\"✓ Created alarm: {alarm_name_latency}\")\n",
    "        alarms_created.append(alarm_name_latency)\n",
    "        \n",
    "        # High error rate alarm\n",
    "        print(\"\\n[2/4] Creating high error rate alarm...\")\n",
    "        alarm_name_errors = f\"{endpoint_name}-high-errors\"\n",
    "        \n",
    "        cloudwatch_client.put_metric_alarm(\n",
    "            AlarmName=alarm_name_errors,\n",
    "            ComparisonOperator='GreaterThanThreshold',\n",
    "            EvaluationPeriods=1,\n",
    "            MetricName='ModelInvocation4XXErrors',\n",
    "            Namespace='AWS/SageMaker',\n",
    "            Period=300,\n",
    "            Statistic='Sum',\n",
    "            Threshold=10.0,\n",
    "            ActionsEnabled=False,\n",
    "            AlarmDescription=f'Alarm when 4XX errors exceed 10 in 5 minutes',\n",
    "            Dimensions=[\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName', 'Value': 'AllTraffic'}\n",
    "            ]\n",
    "        )\n",
    "        print(f\"✓ Created alarm: {alarm_name_errors}\")\n",
    "        alarms_created.append(alarm_name_errors)\n",
    "        \n",
    "        # CPU utilization alarm\n",
    "        print(\"\\n[3/4] Creating CPU utilization alarm...\")\n",
    "        alarm_name_cpu = f\"{endpoint_name}-high-cpu\"\n",
    "        \n",
    "        cloudwatch_client.put_metric_alarm(\n",
    "            AlarmName=alarm_name_cpu,\n",
    "            ComparisonOperator='GreaterThanThreshold',\n",
    "            EvaluationPeriods=2,\n",
    "            MetricName='CPUUtilization',\n",
    "            Namespace='/aws/sagemaker/Endpoints',\n",
    "            Period=300,\n",
    "            Statistic='Average',\n",
    "            Threshold=80.0,  # 80%\n",
    "            ActionsEnabled=False,\n",
    "            AlarmDescription=f'Alarm when CPU utilization exceeds 80%',\n",
    "            Dimensions=[\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName', 'Value': 'AllTraffic'}\n",
    "            ]\n",
    "        )\n",
    "        print(f\"✓ Created alarm: {alarm_name_cpu}\")\n",
    "        alarms_created.append(alarm_name_cpu)\n",
    "        \n",
    "        # 2. Create CloudWatch Dashboard\n",
    "        print(\"\\n[4/4] Creating CloudWatch dashboard...\")\n",
    "        dashboard_name = f\"{endpoint_name}-dashboard\"\n",
    "        \n",
    "        dashboard_body = {\n",
    "            \"widgets\": [\n",
    "                {\n",
    "                    \"type\": \"metric\",\n",
    "                    \"properties\": {\n",
    "                        \"metrics\": [\n",
    "                            [\"AWS/SageMaker\", \"ModelLatency\", {\"stat\": \"Average\"}],\n",
    "                            [\".\", \".\", {\"stat\": \"p99\"}]\n",
    "                        ],\n",
    "                        \"period\": 300,\n",
    "                        \"stat\": \"Average\",\n",
    "                        \"region\": PRIMARY_REGION,\n",
    "                        \"title\": \"Model Latency\",\n",
    "                        \"yAxis\": {\"left\": {\"label\": \"Milliseconds\"}},\n",
    "                        \"dimensions\": {\n",
    "                            \"EndpointName\": endpoint_name,\n",
    "                            \"VariantName\": \"AllTraffic\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"metric\",\n",
    "                    \"properties\": {\n",
    "                        \"metrics\": [\n",
    "                            [\"AWS/SageMaker\", \"Invocations\", {\"stat\": \"Sum\"}],\n",
    "                            [\".\", \"Invocation4XXErrors\", {\"stat\": \"Sum\"}],\n",
    "                            [\".\", \"Invocation5XXErrors\", {\"stat\": \"Sum\"}]\n",
    "                        ],\n",
    "                        \"period\": 300,\n",
    "                        \"stat\": \"Sum\",\n",
    "                        \"region\": PRIMARY_REGION,\n",
    "                        \"title\": \"Invocations and Errors\",\n",
    "                        \"dimensions\": {\n",
    "                            \"EndpointName\": endpoint_name,\n",
    "                            \"VariantName\": \"AllTraffic\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"metric\",\n",
    "                    \"properties\": {\n",
    "                        \"metrics\": [\n",
    "                            [\"/aws/sagemaker/Endpoints\", \"CPUUtilization\", {\"stat\": \"Average\"}],\n",
    "                            [\".\", \"MemoryUtilization\", {\"stat\": \"Average\"}]\n",
    "                        ],\n",
    "                        \"period\": 300,\n",
    "                        \"stat\": \"Average\",\n",
    "                        \"region\": PRIMARY_REGION,\n",
    "                        \"title\": \"Resource Utilization\",\n",
    "                        \"yAxis\": {\"left\": {\"label\": \"Percent\"}},\n",
    "                        \"dimensions\": {\n",
    "                            \"EndpointName\": endpoint_name,\n",
    "                            \"VariantName\": \"AllTraffic\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        cloudwatch_client.put_dashboard(\n",
    "            DashboardName=dashboard_name,\n",
    "            DashboardBody=json.dumps(dashboard_body)\n",
    "        )\n",
    "        print(f\"✓ Created dashboard: {dashboard_name}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MONITORING SETUP COMPLETE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\n✓ Alarms created: {len(alarms_created)}\")\n",
    "        for alarm in alarms_created:\n",
    "            print(f\"   • {alarm}\")\n",
    "        \n",
    "        print(f\"\\n✓ Dashboard: {dashboard_name}\")\n",
    "        print(f\"   View at: https://console.aws.amazon.com/cloudwatch/home?region={PRIMARY_REGION}#dashboards:name={dashboard_name}\")\n",
    "        \n",
    "        return {\n",
    "            \"alarms\": alarms_created,\n",
    "            \"dashboard_name\": dashboard_name,\n",
    "            \"dashboard_url\": f\"https://console.aws.amazon.com/cloudwatch/home?region={PRIMARY_REGION}#dashboards:name={dashboard_name}\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error setting up monitoring: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "print(\"✓ Model monitoring function ready\")\n",
    "print(\"\\nTo set up monitoring:\")\n",
    "print(\"  monitoring_info = setup_model_monitoring('your-endpoint-name')\")\n",
    "print(\"\\nMonitoring includes:\")\n",
    "print(\"  • High latency alarm (>5 seconds)\")\n",
    "print(\"  • High error rate alarm (>10 errors/5min)\")\n",
    "print(\"  • High CPU utilization alarm (>80%)\")\n",
    "print(\"  • CloudWatch dashboard with key metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d9dfd",
   "metadata": {},
   "source": [
    "### Step 5: Model Lifecycle Management\n",
    "\n",
    "Implement automated model versioning, A/B testing, and cleanup procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_ab_testing(endpoint_name, new_model_name, traffic_split=0.1):\n",
    "    \"\"\"\n",
    "    Implement A/B testing by updating endpoint with multiple model variants.\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name: Existing endpoint name\n",
    "        new_model_name: Name of the new model to test\n",
    "        traffic_split: Percentage of traffic for new model (0.0-1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with updated endpoint configuration\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"=\"*80)\n",
    "        print(\"IMPLEMENTING A/B TESTING\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Get current endpoint configuration\n",
    "        print(f\"\\n[1/4] Getting current endpoint configuration...\")\n",
    "        endpoint_desc = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        current_config = endpoint_desc['EndpointConfigName']\n",
    "        print(f\"✓ Current config: {current_config}\")\n",
    "        \n",
    "        # Create new endpoint configuration with two variants\n",
    "        print(f\"\\n[2/4] Creating new endpoint configuration with A/B split...\")\n",
    "        new_config_name = f\"{endpoint_name}-ab-{int(time.time())}\"\n",
    "        \n",
    "        # Calculate traffic distribution\n",
    "        new_variant_weight = int(traffic_split * 100)\n",
    "        current_variant_weight = 100 - new_variant_weight\n",
    "        \n",
    "        production_variants = [\n",
    "            {\n",
    "                'VariantName': 'VariantA',\n",
    "                'ModelName': endpoint_desc['ProductionVariants'][0]['VariantName'],\n",
    "                'InitialInstanceCount': 1,\n",
    "                'InstanceType': 'ml.m5.xlarge',\n",
    "                'InitialVariantWeight': current_variant_weight\n",
    "            },\n",
    "            {\n",
    "                'VariantName': 'VariantB',\n",
    "                'ModelName': new_model_name,\n",
    "                'InitialInstanceCount': 1,\n",
    "                'InstanceType': 'ml.m5.xlarge',\n",
    "                'InitialVariantWeight': new_variant_weight\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        sagemaker_client.create_endpoint_config(\n",
    "            EndpointConfigName=new_config_name,\n",
    "            ProductionVariants=production_variants\n",
    "        )\n",
    "        print(f\"✓ Created config: {new_config_name}\")\n",
    "        print(f\"   • Variant A (current): {current_variant_weight}% traffic\")\n",
    "        print(f\"   • Variant B (new): {new_variant_weight}% traffic\")\n",
    "        \n",
    "        # Update endpoint\n",
    "        print(f\"\\n[3/4] Updating endpoint...\")\n",
    "        print(\"⏳ This may take several minutes...\")\n",
    "        \n",
    "        sagemaker_client.update_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=new_config_name\n",
    "        )\n",
    "        \n",
    "        # Wait for update to complete\n",
    "        waiter = sagemaker_client.get_waiter('endpoint_in_service')\n",
    "        waiter.wait(EndpointName=endpoint_name)\n",
    "        \n",
    "        print(f\"✓ Endpoint updated successfully\")\n",
    "        \n",
    "        # Set up variant-specific CloudWatch metrics\n",
    "        print(f\"\\n[4/4] Setting up variant metrics...\")\n",
    "        \n",
    "        for variant in ['VariantA', 'VariantB']:\n",
    "            alarm_name = f\"{endpoint_name}-{variant}-performance\"\n",
    "            \n",
    "            cloudwatch_client.put_metric_alarm(\n",
    "                AlarmName=alarm_name,\n",
    "                ComparisonOperator='GreaterThanThreshold',\n",
    "                EvaluationPeriods=2,\n",
    "                MetricName='ModelLatency',\n",
    "                Namespace='AWS/SageMaker',\n",
    "                Period=300,\n",
    "                Statistic='Average',\n",
    "                Threshold=6000.0,\n",
    "                ActionsEnabled=False,\n",
    "                AlarmDescription=f'Performance monitoring for {variant}',\n",
    "                Dimensions=[\n",
    "                    {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                    {'Name': 'VariantName', 'Value': variant}\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        print(f\"✓ Variant metrics configured\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"A/B TESTING ACTIVE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\n✓ Endpoint: {endpoint_name}\")\n",
    "        print(f\"✓ Traffic split: {current_variant_weight}% / {new_variant_weight}%\")\n",
    "        print(\"\\n📊 Monitor metrics in CloudWatch to compare variants\")\n",
    "        print(\"📝 After sufficient data, promote the better variant to 100%\")\n",
    "        \n",
    "        return {\n",
    "            \"endpoint_name\": endpoint_name,\n",
    "            \"config_name\": new_config_name,\n",
    "            \"variant_a_weight\": current_variant_weight,\n",
    "            \"variant_b_weight\": new_variant_weight,\n",
    "            \"status\": \"Active\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error implementing A/B testing: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def cleanup_old_resources(days_old=7, dry_run=True):\n",
    "    \"\"\"\n",
    "    Clean up old SageMaker resources to manage costs.\n",
    "    \n",
    "    Args:\n",
    "        days_old: Delete resources older than this many days\n",
    "        dry_run: If True, only list resources without deleting\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with cleanup summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"=\"*80)\n",
    "        print(f\"RESOURCE CLEANUP {'(DRY RUN)' if dry_run else ''}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        from datetime import timedelta\n",
    "        cutoff_date = datetime.now() - timedelta(days=days_old)\n",
    "        \n",
    "        cleanup_summary = {\n",
    "            \"endpoints\": [],\n",
    "            \"endpoint_configs\": [],\n",
    "            \"models\": []\n",
    "        }\n",
    "        \n",
    "        # Find old endpoints\n",
    "        print(f\"\\n[1/3] Checking endpoints (older than {days_old} days)...\")\n",
    "        endpoints = sagemaker_client.list_endpoints()\n",
    "        \n",
    "        for endpoint in endpoints.get('Endpoints', []):\n",
    "            endpoint_name = endpoint['EndpointName']\n",
    "            creation_time = endpoint['CreationTime'].replace(tzinfo=None)\n",
    "            \n",
    "            if creation_time < cutoff_date:\n",
    "                print(f\"   • {endpoint_name} (created {creation_time.date()})\")\n",
    "                cleanup_summary[\"endpoints\"].append(endpoint_name)\n",
    "                \n",
    "                if not dry_run:\n",
    "                    sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "                    print(f\"     ✓ Deleted\")\n",
    "        \n",
    "        # Find old endpoint configs\n",
    "        print(f\"\\n[2/3] Checking endpoint configurations...\")\n",
    "        configs = sagemaker_client.list_endpoint_configs()\n",
    "        \n",
    "        for config in configs.get('EndpointConfigs', []):\n",
    "            config_name = config['EndpointConfigName']\n",
    "            creation_time = config['CreationTime'].replace(tzinfo=None)\n",
    "            \n",
    "            if creation_time < cutoff_date:\n",
    "                print(f\"   • {config_name} (created {creation_time.date()})\")\n",
    "                cleanup_summary[\"endpoint_configs\"].append(config_name)\n",
    "                \n",
    "                if not dry_run:\n",
    "                    sagemaker_client.delete_endpoint_config(EndpointConfigName=config_name)\n",
    "                    print(f\"     ✓ Deleted\")\n",
    "        \n",
    "        # Find old models\n",
    "        print(f\"\\n[3/3] Checking models...\")\n",
    "        models = sagemaker_client.list_models()\n",
    "        \n",
    "        for model in models.get('Models', []):\n",
    "            model_name = model['ModelName']\n",
    "            creation_time = model['CreationTime'].replace(tzinfo=None)\n",
    "            \n",
    "            if creation_time < cutoff_date:\n",
    "                print(f\"   • {model_name} (created {creation_time.date()})\")\n",
    "                cleanup_summary[\"models\"].append(model_name)\n",
    "                \n",
    "                if not dry_run:\n",
    "                    sagemaker_client.delete_model(ModelName=model_name)\n",
    "                    print(f\"     ✓ Deleted\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CLEANUP SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Endpoints: {len(cleanup_summary['endpoints'])}\")\n",
    "        print(f\"Endpoint Configs: {len(cleanup_summary['endpoint_configs'])}\")\n",
    "        print(f\"Models: {len(cleanup_summary['models'])}\")\n",
    "        \n",
    "        if dry_run:\n",
    "            print(\"\\n⚠️  DRY RUN: No resources were deleted\")\n",
    "            print(\"   Set dry_run=False to actually delete resources\")\n",
    "        else:\n",
    "            print(\"\\n✓ Resources deleted successfully\")\n",
    "        \n",
    "        return cleanup_summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during cleanup: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"✓ Model lifecycle management functions ready\")\n",
    "print(\"\\n1. A/B Testing:\")\n",
    "print(\"   ab_info = implement_ab_testing('endpoint-name', 'new-model-name', traffic_split=0.1)\")\n",
    "print(\"\\n2. Resource Cleanup (dry run):\")\n",
    "print(\"   summary = cleanup_old_resources(days_old=7, dry_run=True)\")\n",
    "print(\"\\n3. Resource Cleanup (execute):\")\n",
    "print(\"   summary = cleanup_old_resources(days_old=7, dry_run=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fd31b",
   "metadata": {},
   "source": [
    "## Summary: Complete AI Assistant Implementation\n",
    "\n",
    "This notebook has demonstrated a production-ready AI Assistant with:\n",
    "\n",
    "### ✅ Part 1: Foundation Model Benchmarking\n",
    "- Evaluated Claude and Titan models on financial domain tasks\n",
    "- Measured latency, quality (similarity scores), and cost\n",
    "- Created data-driven model selection strategy\n",
    "\n",
    "### ✅ Part 2: Flexible Architecture\n",
    "- AWS AppConfig for dynamic model routing\n",
    "- Lambda-based model abstraction layer\n",
    "- API Gateway integration for external access\n",
    "\n",
    "### ✅ Part 3: Resilient System Design\n",
    "- Step Functions circuit breaker pattern\n",
    "- Automatic fallback to secondary models\n",
    "- Graceful degradation with regulation-compliant responses\n",
    "- CloudFormation templates for cross-region deployment\n",
    "- Route 53 DNS failover for high availability\n",
    "\n",
    "### ✅ Part 4: Model Customization & Lifecycle\n",
    "- SageMaker fine-tuning with HuggingFace\n",
    "- Model deployment to real-time endpoints\n",
    "- CloudWatch monitoring and alerting\n",
    "- A/B testing for model comparison\n",
    "- Automated resource cleanup\n",
    "\n",
    "### 🎯 Key Features Implemented:\n",
    "1. **Multi-model support** with automatic selection\n",
    "2. **Fault tolerance** with circuit breakers and fallbacks\n",
    "3. **High availability** with cross-region deployment\n",
    "4. **Monitoring & alerting** with CloudWatch\n",
    "5. **Model versioning** and A/B testing\n",
    "6. **Cost optimization** with automated cleanup\n",
    "\n",
    "### 📚 Next Steps:\n",
    "- Request GPU quota for actual model fine-tuning\n",
    "- Deploy to production with custom domain\n",
    "- Configure SNS notifications for alarms\n",
    "- Implement model drift detection\n",
    "- Add authentication/authorization (API keys, Cognito)\n",
    "- Set up CI/CD pipeline for automated deployments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AWS-BEDROCK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
