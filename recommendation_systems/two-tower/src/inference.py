"""
Real-Time Similarity Search for Auction Items

This module demonstrates the "Stage 1 Retrieval" step in a two-stage
ranking system. It encodes user queries and finds similar items using
cosine similarity against pre-computed embeddings.

In production:
    - Query encoding: AWS Lambda function (real-time, <50ms)
    - Similarity search: Amazon OpenSearch k-NN query
    - Returns: Top 50 candidate items ‚Üí passed to Stage 2 re-ranker

Demo: Uses embeddings generated by etl_pipeline.py for search.
"""

import json
import numpy as np
import torch
from transformers import DistilBertTokenizer
from sklearn.metrics.pairwise import cosine_similarity
from model import AuctionQueryEncoder


# ===== Load Pre-Computed Item Embeddings =====
def load_item_embeddings(filepath='item_embeddings.json'):
    """
    Load item embeddings from file.
    
    In production:
        - Embeddings stored in Amazon OpenSearch Service
        - k-NN search handled by OpenSearch (HNSW algorithm)
        - No need to load all embeddings into memory
    
    Returns:
        Tuple of (item_ids, embeddings, metadata)
    """
    item_ids = []
    embeddings = []
    metadata = []
    
    with open(filepath, 'r') as f:
        lines = f.readlines()
        
        # Parse NDJSON format (skip index actions)
        for i in range(0, len(lines), 2):
            doc = json.loads(lines[i+1])  # Document line
            
            item_ids.append(doc['item_id'])
            embeddings.append(doc['embedding'])
            metadata.append(doc['metadata'])
    
    embeddings = np.array(embeddings)
    
    print(f"‚úÖ Loaded {len(item_ids)} item embeddings ({embeddings.shape[1]}-dim)")
    return item_ids, embeddings, metadata


# ===== Query Encoding =====
def encode_query(query_text, model, tokenizer, device='cpu'):
    """
    Encode user query to 128-dim embedding.
    
    In production (AWS Lambda):
        - Input: User search query (e.g., "vintage watches")
        - Model: Lightweight query encoder (<100MB)
        - Output: 128-dim vector for OpenSearch k-NN
        - Latency: ~20-30ms
    
    Args:
        query_text: User's search query string
        model: AuctionQueryEncoder instance
        tokenizer: DistilBERT tokenizer
        device: 'cpu' or 'cuda'
    
    Returns:
        query_embedding: (128,) numpy array
    """
    model.eval()
    model.to(device)
    
    # Tokenize query
    encoded = tokenizer(
        [query_text],
        padding=True,
        truncation=True,
        max_length=128,
        return_tensors='pt'
    ).to(device)
    
    # Generate embedding
    with torch.no_grad():
        query_embedding = model(
            input_ids=encoded['input_ids'],
            attention_mask=encoded['attention_mask']
        )
    
    return query_embedding.cpu().numpy()[0]


# ===== Cosine Similarity Search =====
def find_similar_items(query_text, item_ids, embeddings, metadata, 
                       model, tokenizer, top_k=10, device='cpu'):
    """
    Find top-k most similar items to a user query.
    
    In production (OpenSearch k-NN query):
    ```
    POST /auction-items/_search
    {
      "size": 50,
      "query": {
        "knn": {
          "embedding": {
            "vector": [0.123, -0.456, ...],  # Query embedding
            "k": 50
          }
        }
      }
    }
    ```
    
    Args:
        query_text: User search query
        item_ids: List of item IDs
        embeddings: (N, 128) numpy array of item embeddings
        metadata: List of item metadata dicts
        model: Query encoder model
        tokenizer: Tokenizer
        top_k: Number of results to return
        device: 'cpu' or 'cuda'
    
    Returns:
        List of tuples: (item_id, similarity_score, metadata)
    """
    # Step 1: Encode query
    query_embedding = encode_query(query_text, model, tokenizer, device)
    
    # Step 2: Compute cosine similarity
    # Note: embeddings are already L2-normalized, so dot product = cosine similarity
    similarities = cosine_similarity([query_embedding], embeddings)[0]
    
    # Step 3: Get top-k indices
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    # Step 4: Format results
    results = []
    for idx in top_indices:
        results.append({
            'item_id': item_ids[idx],
            'similarity_score': float(similarities[idx]),
            'metadata': metadata[idx]
        })
    
    return results


# ===== Display Results =====
def display_results(query, results):
    """
    Pretty-print search results.
    """
    print("\n" + "="*70)
    print(f"üîç Query: \"{query}\"")
    print("="*70)
    
    for i, result in enumerate(results, 1):
        meta = result['metadata']
        print(f"\n{i}. {meta['title']}")
        print(f"   Item ID: {result['item_id']}")
        print(f"   Similarity: {result['similarity_score']:.4f}")
        print(f"   Category: {meta['category']}")
        print(f"   Price: ${meta['current_price']:,.2f}")
        print(f"   Bids: {meta['bid_count']} | Seller Rating: {meta['seller_rating']}/5.0")
    
    print("\n" + "="*70)


# ===== Interactive Search Demo =====
def interactive_search(item_ids, embeddings, metadata, model, tokenizer, device='cpu'):
    """
    Run an interactive search session.
    """
    print("\n" + "="*70)
    print("üîé Interactive Auction Search (Two-Tower Retrieval)")
    print("="*70)
    print("\nType your search query (or 'quit' to exit):")
    
    while True:
        query = input("\n> ").strip()
        
        if query.lower() in ['quit', 'exit', 'q']:
            print("Goodbye!")
            break
        
        if not query:
            continue
        
        # Find similar items
        results = find_similar_items(
            query_text=query,
            item_ids=item_ids,
            embeddings=embeddings,
            metadata=metadata,
            model=model,
            tokenizer=tokenizer,
            top_k=5,
            device=device
        )
        
        # Display results
        display_results(query, results)


# ===== Main Entry Point =====
def main():
    """
    Run similarity search demo.
    """
    print("="*70)
    print("Stage 1 Retrieval Demo: Auction Item Similarity Search")
    print("="*70)
    
    # Load item embeddings
    print("\nüì• Loading item embeddings...")
    item_ids, embeddings, metadata = load_item_embeddings('item_embeddings.json')
    
    # Initialize query encoder
    print("\nüß† Loading query encoder...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"   Device: {device}")
    
    model = AuctionQueryEncoder(embedding_dim=128)
    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
    
    # In production: Load fine-tuned query encoder from S3
    # model_path = 's3://auction-models/query-encoder/v1.2/model.pth'
    # model.load_state_dict(torch.load(model_path))
    
    # Example queries
    example_queries = [
        "luxury watches",
        "gaming console",
        "rare collectibles"
    ]
    
    print("\n" + "="*70)
    print("Running example queries...")
    print("="*70)
    
    for query in example_queries:
        results = find_similar_items(
            query_text=query,
            item_ids=item_ids,
            embeddings=embeddings,
            metadata=metadata,
            model=model,
            tokenizer=tokenizer,
            top_k=3,
            device=device
        )
        display_results(query, results)
    
    # Start interactive mode
    print("\n" + "="*70)
    print("üí° Try your own queries!")
    print("="*70)
    interactive_search(item_ids, embeddings, metadata, model, tokenizer, device)


if __name__ == "__main__":
    import os
    
    # Check if embeddings file exists
    if not os.path.exists('item_embeddings.json'):
        print("‚ùå Error: item_embeddings.json not found!")
        print("\nPlease run the ETL pipeline first:")
        print("   python src/etl_pipeline.py")
        exit(1)
    
    main()
